# XANPAN::AGENTS v2.1

## MetodologÃ­a de Desarrollo Ãgil Post-Humano

*Cuando los agentes IA son los desarrolladores y los humanos gobiernan la direcciÃ³n, el valor y la Ã©tica*

Basado en los marcos de **Allan Kelly** (Xanpan, Continuous Digital, OKRs in Agile, User Stories)
Fundamentado en **Human-Centered AI (HCAI)** (Shneiderman, Xu, et al.)

Febrero 2026

---

## Ãndice

0. [Manifiesto: La Gran InversiÃ³n](#0-manifiesto-la-gran-inversiÃ³n)
1. [Fundamento FilosÃ³fico: HCAI como Acelerador](#1-fundamento-filosÃ³fico-hcai-como-acelerador)
2. [Los Roles Humanos: Superhumanos, no Supervisores](#2-los-roles-humanos-superhumanos-no-supervisores)
3. [User Stories: El Contrato Humano-Agente](#3-user-stories-el-contrato-humano-agente)
4. [Modelo Temporal: Del Sprint al Flujo Continuo](#4-modelo-temporal-del-sprint-al-flujo-continuo)
5. [El Tablero Neural](#5-el-tablero-neural)
6. [EconomÃ­a de Tokens: De Story Points a MÃ©tricas Reales](#6-economÃ­a-de-tokens-de-story-points-a-mÃ©tricas-reales)
7. [Calidad: El Escudo contra la AlucinaciÃ³n](#7-calidad-el-escudo-contra-la-alucinaciÃ³n)
8. [OKRs: Gobernanza EstratÃ©gica del Enjambre](#8-okrs-gobernanza-estratÃ©gica-del-enjambre)
9. [Arquitectura del Enjambre Auto-Evolutivo](#9-arquitectura-del-enjambre-auto-evolutivo)
10. [Human-in-the-Loop: Los Cuatro Loops de Gobernanza HCAI](#10-human-in-the-loop-los-cuatro-loops-de-gobernanza-hcai)
11. [Digital Continuo con Agentes: El Software Longevo](#11-digital-continuo-con-agentes-el-software-longevo)
12. [Observabilidad y Retrospectiva AnalÃ­tica](#12-observabilidad-y-retrospectiva-analÃ­tica)
13. [Seguridad y Gobernanza Multi-Nivel](#13-seguridad-y-gobernanza-multi-nivel)
14. [Velocidad Exponencial: El Meta-Principio](#14-velocidad-exponencial-el-meta-principio)
15. [Modos de Fallo y Circuit Breakers](#15-modos-de-fallo-y-circuit-breakers)
16. [Modelo de TransiciÃ³n: Del Equipo Humano al Enjambre](#16-modelo-de-transiciÃ³n-del-equipo-humano-al-enjambre)
17. [SÃ­ntesis: La MetodologÃ­a Completa](#17-sÃ­ntesis-la-metodologÃ­a-completa)
18. [ApÃ©ndice: Korvoâ€“Korax como Proof of Concept](#18-apÃ©ndice-korvokorax-como-proof-of-concept)

---

# 0. Manifiesto: La Gran InversiÃ³n

> *"Xanpan is team-centric: work flows to the team, not the team to work."*
> â€” Allan Kelly, Xanpan

La verdad de Kelly permanece intacta. El equipo es la unidad atÃ³mica. El trabajo fluye hacia Ã©l, no al revÃ©s. Pero la composiciÃ³n del equipo acaba de sufrir una mutaciÃ³n de especie.

Estamos en febrero de 2026. Los modelos de lenguaje escriben cÃ³digo de producciÃ³n, generan tests, revisan PRs, despliegan servicios y depuran fallos en tiempo real. **La velocidad es frenÃ©tica. La exponencialidad es real. Y no estamos al inicio de esta curva: estamos en el codo.** Cada seis meses, las capacidades de los modelos se duplican. Cada trimestre, nuevas herramientas colapsan lo que ayer requerÃ­a equipos enteros. Esta metodologÃ­a no puede escribirse con cautela. Debe escribirse con la urgencia de quien documenta una revoluciÃ³n mientras ocurre.

Xanpan::Agents v2.1 no es una adaptaciÃ³n tÃ­mida del agile clÃ¡sico. Es una **reconstrucciÃ³n desde la base semÃ¡ntica** de quÃ© significa desarrollar software cuando los ejecutores cambian de especie cognitiva. Donde el agile clÃ¡sico tenÃ­a 5-8 desarrolladores humanos, ahora hay un **enjambre de agentes IA** produciendo cÃ³digo, configuraciones, tests y artefactos. Donde habÃ­a un Scrum Master facilitando dinÃ¡micas sociales, ahora hay un **Operador** orquestando topologÃ­as de modelos. El Ãºnico rol que sobrevive casi intacto es el **Product Owner**: la conciencia humana que define QUÃ‰ construir y POR QUÃ‰.

> âš¡ **LA DISCONTINUIDAD**
>
> No estamos optimizando el proceso existente. Estamos presenciando una discontinuidad. Cuando cambias la especie del ejecutor, cada concepto Ã¡gil debe ser reconstruido desde sus axiomas. EstimaciÃ³n, velocidad, iteraciÃ³n, pair programming, retrospectiva, planning poker: todos nacieron como respuestas a limitaciones humanas. Cuando esas limitaciones desaparecen, las respuestas deben transformarse o morir.

## 0.1 Lo que permanece invariante

No todo cambia. Los principios de Kelly que son verdades sobre la naturaleza del software y del valor â€”no sobre la naturaleza del desarrolladorâ€” sobreviven intactos y se amplifican:

- **Cada historia debe entregar valor de negocio.** (Kelly: "Una user story sin beneficio de negocio no tiene razÃ³n de existir.") Los agentes ejecutan mÃ¡s rÃ¡pido, pero ejecutar rÃ¡pido algo sin valor es destruir recursos mÃ¡s rÃ¡pido.
- **OKRs como gobernanza estratÃ©gica.** (Kelly: "Escribir OKRs trimestrales es fundamentalmente una pregunta de estrategia.") Los agentes necesitan direcciÃ³n mÃ¡s que nunca; sin OKRs, un enjambre es una fuerza sin vector.
- **La calidad es gratis si inviertes en ella.** (Crosby/Kelly: "Quality is free.") Con agentes, se amplifica: TDD, linting, evals no tienen coste cognitivo. El escudo contra la alucinaciÃ³n es barato si lo integras desde el dÃ­a cero.
- **Software como activo vivo.** (Kelly/Continuous Digital: "El software no puede ser un activo estÃ¡tico. Se degrada porque el mundo cambia.") Con agentes, la inversiÃ³n continua se vuelve econÃ³micamente trivial. La excusa de "no hay presupuesto para mantenimiento" muere.
- **Visualizar todo.** (Kelly: "Si no podemos ver, no podemos aprender.") El tablero es el sistema nervioso. Con agentes, se convierte en dashboard en tiempo real.

## 0.2 Lo que colapsa

Conceptos que fueron respuestas brillantes a limitaciones humanas y que ahora pierden su razÃ³n de ser mecÃ¡nica:

- **EstimaciÃ³n basada en esfuerzo humano.** Planning poker, story points, velocidad en puntos/sprint: todo medÃ­a capacidad cognitiva humana. Los agentes no tienen "dÃ­as buenos" ni "dÃ­as malos." El coste es predecible en tokens.
- **Iteraciones de 1-2 semanas como unidad temporal.** Cuando un agente implementa una historia en minutos, la iteraciÃ³n de dos semanas pierde su razÃ³n mecÃ¡nica. El ritmo ahora es continuo.
- **Pair programming como prÃ¡ctica social.** Era herramienta de calidad + transferencia de conocimiento entre humanos. Los agentes no necesitan socializar conocimiento; lo comparten via context engineering.
- **Retrospectivas como espacio de reflexiÃ³n emocional.** Los agentes no experimentan frustraciÃ³n, conflicto interpersonal ni pÃ©rdida de motivaciÃ³n. La retro se transforma en anÃ¡lisis operacional puro.

## 0.3 Lo que emerge

Nuevos conceptos que no tenÃ­an equivalente en equipos humanos y que definen el territorio inexplorado de esta metodologÃ­a. **AquÃ­ es donde la revoluciÃ³n se manifiesta:**

- **EvaluaciÃ³n continua (Evals) como TDD organizacional.** Verificar que los agentes no alucinan, no regresan, mantienen calidad. Es la prÃ¡ctica tÃ©cnica obligatoria de esta era.
- **Coste por token como mÃ©trica de eficiencia.** Reemplaza la velocidad en puntos. Cuantificable, comparable, directamente vinculado a valor econÃ³mico.
- **Context engineering como disciplina.** La ventana de contexto del LLM es el recurso mÃ¡s escaso y valioso. Gestionarlo es la nueva competencia que no existÃ­a en equipos humanos.
- **Enjambre auto-evolutivo.** Los agentes no solo ejecutan: optimizan sus propios prompts, proponen mejoras a sus evals, y sugieren reconfiguraciones de topologÃ­a. El enjambre aprende.
- **Backlog predictivo.** Los agentes analizan patrones de uso, mÃ©tricas de producto y OKRs para proponer historias antes de que el PO las escriba. El PO pasa de escribir historias a curar y aprobar propuestas.
- **Despliegue continuo sin staging.** Con evals suficientemente robustos y feature flags, el concepto de "ambiente de staging" se comprime. Ship fast, eval faster, rollback instantÃ¡neo.
- **Gobernanza multi-nivel HCAI.** Humano-en-el-loop, OrganizaciÃ³n-en-el-loop, Ecosistema-en-el-loop, Sociedad-en-el-loop. Marcos de Shneiderman y Xu integrados como estructura de seguridad que HABILITA velocidad.
- **Modos de fallo y circuit breakers.** El happy path no es suficiente. La metodologÃ­a incluye patrones explÃ­citos de degradaciÃ³n, contenciÃ³n y recuperaciÃ³n ante fallos sistÃ©micos del enjambre.

---

# 1. Fundamento FilosÃ³fico: HCAI como Acelerador

> *"AI should achieve both high automation and high human control to deliver systems that are reliable, safe, and trustworthy."*
> â€” Ben Shneiderman, HCAI Framework

La mayorÃ­a de las metodologÃ­as ven la gobernanza como un **freno**. Xanpan::Agents la ve como un **acelerador**. Esta aparente paradoja se resuelve con el marco de **Human-Centered Artificial Intelligence (HCAI)**, cuyo insight central destruye el falso dilema entre automatizaciÃ³n y control.

## 1.1 El insight de Shneiderman: No hay trade-off

El marco bidimensional de Shneiderman (2020) demuestra que automatizaciÃ³n y control humano no son extremos de un espectro. Son dimensiones independientes. El cuadrante objetivo de HCAI es el superior derecho: ALTA automatizaciÃ³n Y ALTO control humano simultÃ¡neamente.

Esto destruye la intuiciÃ³n falsa de que "mÃ¡s autonomÃ­a de agentes = menos control humano." **No. MÃ¡s autonomÃ­a de agentes + mÃ¡s puntos de control estratÃ©gico = mejor resultado que cualquiera por separado.** Los agentes ejecutan a velocidad de mÃ¡quina. Los humanos gobiernan en los nodos de valor y riesgo. Ambos al mÃ¡ximo.

> ðŸ”® **PRINCIPIO HCAI EN XANPAN::AGENTS**
>
> La autonomÃ­a total del enjambre en la ejecuciÃ³n tÃ©cnica es posible PORQUE existe gobernanza humana total en los nodos estratÃ©gicos. No es a pesar de la gobernanza. Es gracias a ella. Cuanto mÃ¡s robusto el marco de control, mÃ¡s agresiva puede ser la autonomÃ­a.

## 1.2 Las cuatro metÃ¡foras de diseÃ±o

Shneiderman propone cuatro metÃ¡foras para sistemas IA. En Xanpan::Agents, cada una tiene una manifestaciÃ³n concreta:

| MetÃ¡fora HCAI | DescripciÃ³n | ManifestaciÃ³n en Xanpan::Agents |
|---|---|---|
| **Supertools** | Interfaces que amplifican la intenciÃ³n humana | El PO usa agentes-planificadores como superherramientas que amplifican su capacidad de definir y refinar historias 100x |
| **Tele-bots** | Efectores remotos bajo autoridad humana continua | Agentes-coder como tele-bots: ejecutan cÃ³digo bajo la direcciÃ³n estratÃ©gica del Operador, con feedback continuo |
| **Active Appliances** | AutonomÃ­a dentro de lÃ­mites bien definidos | Agentes de CI/CD, linting, eval: operan autÃ³nomamente dentro de lÃ­mites estrictos configurados |
| **Control Centers** | OrquestaciÃ³n humana de sistemas automatizados | El dashboard del Operador: centro de control que orquesta el enjambre con visibilidad total y capacidad de intervenciÃ³n |

## 1.3 El TriÃ¡ngulo THE de Xu

Wei Xu (2019) propone el **TriÃ¡ngulo TecnologÃ­a-Factores Humanos-Ã‰tica (THE)**: toda soluciÃ³n IA viable reside en la zona de integraciÃ³n Ã³ptima donde las tres perspectivas se solapan. Si desarrollas IA solo con lente tecnolÃ³gica, arriesgas daÃ±o. Si solo con lente Ã©tica, pierdes innovaciÃ³n. Si solo con lente humana, pierdes escalabilidad.

En Xanpan::Agents, el TriÃ¡ngulo THE se operacionaliza asÃ­:

- **TecnologÃ­a:** Model Router, context engineering, evals, CI/CD. El stack tÃ©cnico que habilita la ejecuciÃ³n.
- **Factores Humanos:** El PO como conciencia de valor, el Operador como ingeniero de enjambre, los puntos de intervenciÃ³n human-in-the-loop.
- **Ã‰tica:** ClasificaciÃ³n de riesgo por historia, principio de mÃ­nimo privilegio por agente, gobernanza multi-nivel, auditorÃ­a continua.

## 1.4 HCAI JerÃ¡rquico: Los cuatro loops

Xu y Gao (2025) extienden HCAI a un modelo multi-nivel: **hHCAI (Hierarchical Human-Centered AI)**. Cuatro niveles de gobernanza, cada uno con su "loop" de control:

| Loop HCAI | Alcance | ImplementaciÃ³n en Xanpan::Agents |
|---|---|---|
| **Human-in-the-loop** | InteracciÃ³n individuo-agente | PO acepta/rechaza historias. Operador aprueba acciones destructivas. Cada humano tiene override absoluto. |
| **Organization-in-the-loop** | Contexto organizacional | OKRs alinean enjambre con estrategia de la organizaciÃ³n. Presupuesto de tokens aprobado por liderazgo. Cultura de calidad como norma. |
| **Ecosystem-in-the-loop** | MÃºltiples sistemas IA interconectados | El enjambre como parte del ecosistema tÃ©cnico de la organizaciÃ³n. Interoperabilidad via MCP. CoordinaciÃ³n con otros sistemas IA. |
| **Society-in-the-loop** | Impacto macrosocial | Cumplimiento regulatorio (EU AI Act, NIST AIRMF). ConsideraciÃ³n de impacto laboral. Transparencia y auditabilidad. |

> ðŸš€ **POR QUÃ‰ HCAI ACELERA EN VEZ DE FRENAR**
>
> Sin gobernanza, cada decisiÃ³n requiere deliberaciÃ³n ad hoc. Con gobernanza estructurada, las decisiones estÃ¡n pre-tomadas: el agente SABE quÃ© puede hacer autÃ³nomamente y quÃ© requiere aprobaciÃ³n. No hay ambigÃ¼edad. No hay paralizaciÃ³n. La gobernanza es el pre-cÃ¡lculo que elimina fricciÃ³n en runtime. MÃ¡s estructura = mÃ¡s velocidad.

## 1.5 Modelo de Madurez HCAI para Xanpan::Agents

Winby y Xu (2025) proponen cinco niveles de madurez organizacional HCAI. Adaptados a Xanpan::Agents:

| Nivel | Estado | CaracterÃ­sticas en Xanpan::Agents |
|---|---|---|
| **1 - Ad Hoc** | ExploraciÃ³n | Uso esporÃ¡dico de agentes. Sin evals formales. Sin OKRs de enjambre. PO y Operador son la misma persona. |
| **2 - Repetible** | AdopciÃ³n inicial | Evals bÃ¡sicos en CI. Board implementado. PO y Operador diferenciados. Historias con criterios de aceptaciÃ³n. |
| **3 - Definido** | Estandarizado | MetodologÃ­a completa adoptada. Context engineering formalizado. Model Router activo. MÃ©tricas de coste y calidad rastreadas. |
| **4 - Gestionado** | Optimizado | Enjambre auto-evolutivo activo. Backlog predictivo operando. Despliegue continuo con evals robustos. AnÃ¡lisis retrospectivo data-driven. |
| **5 - Optimizante** | Trascendente | El enjambre propone OKRs. Meta-agentes optimizan la metodologÃ­a misma. La organizaciÃ³n opera como sistema inteligente humano-IA integrado. |

---

# 2. Los Roles Humanos: Superhumanos, no Supervisores

> *"The true value of AI lies in complementing human strengthsâ€”judgment, creativity, empathy, ethical reasoningâ€”while compensating for human limitations."*
> â€” Wei Xu, HCAI Guiding Principles

HCAI insiste: la IA debe **aumentar y empoderar** las capacidades humanas, no sustituirlas. En Xanpan::Agents, esto se manifiesta de forma radical: los humanos del sistema no son "supervisores pasivos" que aprueban tickets. Son **superhumanos operando con capacidades amplificadas 100x por el enjambre.**

## 2.1 Product Owner: El Super-PO

En Scrum clÃ¡sico, el PO estÃ¡ permanentemente en cuello de botella: definir historias, priorizar backlog, atender a stakeholders, negociar con el equipo, asistir a ceremonias. En Xanpan::Agents, el PO se libera de la mecÃ¡nica y se eleva a la estrategia pura.

### Capacidades amplificadas por el enjambre

- **Captura de necesidades acelerada:** El PO habla con clientes y stakeholders. Un agente-analista transcribe, sintetiza y propone borradores de historias en formato Who/What/Why con criterios de aceptaciÃ³n sugeridos. El PO refina en minutos lo que antes tomaba dÃ­as.
- **PriorizaciÃ³n asistida por datos:** Agentes-analistas cruzan mÃ©tricas de producto, patrones de uso y OKRs para sugerir prioridades. El PO decide, pero decide informado con anÃ¡lisis que antes requerÃ­a un equipo de data.
- **Backlog predictivo:** Agentes proponen historias basadas en patrones detectados. El PO pasa de ESCRIBIR historias a CURAR y APROBAR propuestas. InversiÃ³n del flujo creativo.
- **ValidaciÃ³n instantÃ¡nea:** Cuando el PO escribe una historia, un agente la analiza inmediatamente: Â¿Es testable? Â¿Tiene criterios de aceptaciÃ³n claros? Â¿Hay dependencias? Â¿El valor estÃ¡ cuantificado? Feedback en segundos, no en la prÃ³xima planning meeting.

### Responsabilidades irreductiblemente humanas

Lo que el PO hace y que ningÃºn agente puede hacer:

- **Juicio de valor:** Â¿Esta feature sirve a nuestros usuarios reales? Â¿Alinea con nuestra visiÃ³n? Los agentes optimizan; los humanos deciden QUÃ‰ optimizar.
- **EmpatÃ­a con el usuario:** Entender dolor, frustraciÃ³n, deseo. Los agentes procesan datos de uso; el PO entiende personas.
- **DecisiÃ³n Ã©tica:** Â¿DeberÃ­amos construir esto aunque podamos? El PO es el gatekeeper Ã©tico del producto.
- **AceptaciÃ³n final:** Cada historia completada pasa por aprobaciÃ³n humana del PO. Sin excepciones. Este es el nÃºcleo del human-in-the-loop de HCAI.

## 2.2 Operador: El Ingeniero de Enjambre

El Scrum Master facilitaba dinÃ¡micas sociales: resolvÃ­a conflictos, mantenÃ­a moral, removÃ­a impedimentos. El Operador es una especie completamente diferente: es un **ingeniero de sistemas inteligentes** que configura, calibra y optimiza el enjambre.

### Capacidades amplificadas

- **Context engineering:** Mantiene los archivos CONVENTIONS.md, ARCHITECTURE.md, STACK.md que alimentan a los agentes. Equivalente a mantener el "modelo mental compartido" de Kelly, pero externalizado y versionado.
- **TopologÃ­a de enjambre:** Define quÃ© agentes participan, con quÃ© modelos, quÃ© herramientas (AgentSkills) disponibles, quÃ© permisos. Puede reconfigurar en minutos sin "forming-storming."
- **Model Router:** Configura routing de tareas al modelo Ã³ptimo por coste/capacidad. Optimiza la economÃ­a de tokens del enjambre.
- **Monitor de calidad:** Observa mÃ©tricas del enjambre: tasa de alucinaciÃ³n, tasa de Ã©xito de tool-calling, coste por historia, acceptance rate. Interviene cuando detecta degradaciÃ³n.

### Responsabilidades irreductiblemente humanas

- **AprobaciÃ³n de acciones destructivas:** Delete de datos, deploy a producciÃ³n, comunicaciones externas: requieren aprobaciÃ³n explÃ­cita del Operador.
- **Cambios arquitectÃ³nicos:** Decisiones que afectan la estructura fundamental del sistema requieren juicio humano.
- **Actualizaciones de modelo:** Cambiar el modelo base de un agente requiere evals de regresiÃ³n y aprobaciÃ³n del Operador.
- **Retrospectiva analÃ­tica:** Conduce el anÃ¡lisis periÃ³dico de rendimiento del enjambre con el PO.

### Context hygiene: el Sentinel como mantenedor

El context engineering es trabajo cognitivo significativo. Si el Operador gasta 40% de su tiempo manteniendo context files, la atenciÃ³n como recurso soberano empieza a gritar. La soluciÃ³n: **el Sentinel mantiene context files y el Operador solo aprueba diffs.**

Modelo de context hygiene:

1. **DetecciÃ³n automÃ¡tica de drift:** El Sentinel compara el estado real del codebase (estructura de archivos, dependencias, patrones de cÃ³digo) con lo declarado en ARCHITECTURE.md y CONVENTIONS.md. Cuando detecta divergencia, genera un diff propuesto.
2. **ActualizaciÃ³n propuesta como PR:** El diff al context file se presenta como PR con justificaciÃ³n. El Operador revisa y aprueba/ajusta.
3. **Versionado estricto:** Los context files estÃ¡n en git. Cada cambio tiene autor (Sentinel o Operador), timestamp, y justificaciÃ³n. Es auditable.
4. **ValidaciÃ³n cruzada:** Al inicio de cada sesiÃ³n de agente, un check rÃ¡pido verifica que los context files son coherentes entre sÃ­ y con el codebase real. Incoherencia = alerta al Operador.

> âš¡ **EL SUPER-HUMANO DE HCAI**
>
> En Xanpan::Agents, un PO + un Operador + el enjambre producen lo que antes requerÃ­a un equipo de 8-12 personas. No porque los humanos trabajen mÃ¡s, sino porque trabajan DIFERENTE: en el estrato donde su juicio es irreemplazable, amplificados por agentes que ejecutan el estrato mecÃ¡nico a velocidad de mÃ¡quina. Esto es human augmentation real, no marketing.

## 2.3 Roles SatÃ©lite: MÃ¡s allÃ¡ del software puro

El modelo PO + Operador asume un producto de software. Pero el software no existe en el vacÃ­o. Hay normativa, polÃ­tica interna, usuarios no-tÃ©cnicos, dominios especializados. Xanpan::Agents necesita un escape hatch para dominios complejos.

### El problema

En un hospital, hay normativa clÃ­nica. En una fintech, hay regulaciÃ³n bancaria. En gobierno, hay polÃ­tica interna y usuarios no-tÃ©cnicos. El PO no puede ser experto simultÃ¡neamente en valor de negocio, dominio clÃ­nico, regulaciÃ³n financiera y experiencia de usuario. Y el Operador no puede ser simultÃ¡neamente ingeniero de enjambre y auditor de cumplimiento.

### Roles satÃ©lite definidos

Los roles satÃ©lite **no** son miembros permanentes del equipo. Son **interfaces humanas que el enjambre consulta a demanda**, amplificadas por agentes especializados:

| Rol satÃ©lite | CuÃ¡ndo se activa | CÃ³mo interactÃºa con el enjambre | Ejemplo |
|---|---|---|---|
| **Domain Expert** | Historias que requieren conocimiento especializado | Un agente-analista prepara briefing del contexto tÃ©cnico; el expert valida supuestos y restricciones de dominio | MÃ©dico validando lÃ³gica de dosificaciÃ³n |
| **Compliance Officer** | Historias clasificadas como regulatorias o con impacto legal | Agente-compliance pre-analiza contra marco regulatorio conocido; el officer valida y firma | Auditor revisando cumplimiento GDPR |
| **UX Researcher** | Historias que afectan experiencia de usuario | Agente genera prototipos o flujos; el researcher valida contra investigaciÃ³n de usuarios reales | DiseÃ±ador evaluando flujo de onboarding |
| **Security Analyst** | Historias clasificadas como crÃ­ticas o con superficie de ataque | Agente-security ejecuta anÃ¡lisis estÃ¡tico/dinÃ¡mico; el analyst revisa hallazgos y autoriza | Pentester revisando nueva API expuesta |
| **Stakeholder Rep** | Revisiones de Ciclo o decisiones estratÃ©gicas | Asiste a Retrospectiva AnalÃ­tica como observador con voz; recibe reportes generados por agente-analyst | VP de producto en revisiÃ³n de OKRs |

### Principio de diseÃ±o: amplificaciÃ³n, no burocracia

Los roles satÃ©lite siguen el patrÃ³n HCAI de Supertools: el agente prepara, analiza y sintetiza; el humano especialista juzga, valida y decide. El agente hace el trabajo pesado de recopilaciÃ³n y anÃ¡lisis. El humano aporta los 5 minutos de juicio experto que ningÃºn modelo puede reemplazar.

**Anti-patrÃ³n:** convertir roles satÃ©lite en gates burocrÃ¡ticos que bloquean el flujo. El principio es consulta a demanda, no aprobaciÃ³n en cadena. Si una historia no tiene clasificaciÃ³n regulatoria, el Compliance Officer nunca la ve. Si no tiene superficie de ataque, el Security Analyst nunca la ve.

### Modo dual-hat (equipos pequeÃ±os)

En equipos pequeÃ±os o individuales, una persona puede ocupar mÃºltiples roles. El caso extremo es el operador-PO individual (ver Â§18: Korvo-Korax). En este caso, el PCA (Protocol de Coherencia Atencional) o un equivalente de gobernanza personal compensa la falta de separaciÃ³n de concerns. El Sentinel cobra importancia adicional como "segundo par de ojos" que el humano dual-hat no tiene.

---

# 3. User Stories: El Contrato Humano-Agente

> *"A user story is a placeholder for a conversation. Each story has business benefit."*
> â€” Allan Kelly, Xanpan

La historia de usuario sobrevive como mecanismo central de captura de requisitos. Lo que cambia: la naturaleza de la conversaciÃ³n y la velocidad de resoluciÃ³n.

## 3.1 AnatomÃ­a de una historia en Xanpan::Agents

Cinco elementos: tres heredados de Kelly, dos nuevos para el mundo de agentes:

| Elemento | Origen | Responsable | DescripciÃ³n |
|---|---|---|---|
| **Who/What/Why** | Kelly | PO | Formato clÃ¡sico: "Como [usuario], quiero [funcionalidad], para [beneficio]" |
| **Criterios de aceptaciÃ³n** | Kelly | PO + Agente | Condiciones testables que definen "hecho." El agente sugiere; el PO aprueba. |
| **Valor de negocio (puntos)** | Kelly | PO | EstimaciÃ³n abstracta de valor asignada por PO. |
| **SeÃ±al de complejidad** | NUEVO | Operador/Auto | simple \| estÃ¡ndar \| complejo \| crÃ­tico. Determina tier de modelo via Model Router. |
| **ClasificaciÃ³n de riesgo** | NUEVO | Operador/Auto | lectura \| escritura \| destructiva. Determina si requiere aprobaciÃ³n humana pre-ejecuciÃ³n. |

## 3.2 La conversaciÃ³n humano-agente

En Scrum clÃ¡sico, la conversaciÃ³n sobre una historia ocurre en la planning meeting, dÃ­as despuÃ©s de ser escrita. En Xanpan::Agents, la conversaciÃ³n es **instantÃ¡nea y continua:**

1. **PO escribe historia + criterios de aceptaciÃ³n.** Puede ser borrador imperfecto.
2. **Agente analiza y hace preguntas clarificadoras inmediatamente.** "Â¿El lÃ­mite de 500ms incluye latencia de red? Â¿El 'usuario nuevo' incluye usuarios anÃ³nimos?"
3. **PO refina en ciclos cortos.** La conversaciÃ³n de clarificaciÃ³n que en Scrum toma dÃ­as, aquÃ­ toma minutos.
4. **Agente genera plan de implementaciÃ³n antes de escribir cÃ³digo.** PO u Operador aprueban el plan.
5. **EjecuciÃ³n con feedback continuo.** El agente puede pedir clarificaciÃ³n mid-flight si encuentra ambigÃ¼edad.

## 3.3 JerarquÃ­a: Ã‰picas â†’ Historias â†’ Tareas

La jerarquÃ­a de Kelly se preserva pero las fronteras se comprimen:

- **Ã‰picas:** Objetivos de negocio que mapean directamente a Key Results de OKR. Demasiado grandes para un ciclo de ejecuciÃ³n de agente. Escritas por PO.
- **Historias:** Unidades de valor entregable. Cada una con beneficio de negocio independiente y criterios de aceptaciÃ³n testables. Un agente puede consumir una historia en una sesiÃ³n: minutos a horas, no dÃ­as.
- **Tareas:** Auto-generadas por el agente al descomponer la historia. El humano NO necesita escribir tareas. El agente planifica su propia descomposiciÃ³n.

> âš¡ **CUELLO DE BOTELLA INVERTIDO**
>
> Kelly advierte que backlogs grandes son perjudiciales. En Xanpan::Agents esto se amplifica exponencialmente: los agentes pueden consumir el backlog mÃ¡s rÃ¡pido de lo que el PO puede nutrirlo. El cuello de botella se invierte: ya no es la velocidad de desarrollo sino la velocidad de definiciÃ³n de valor por el humano. El backlog predictivo (agentes proponiendo historias) es la soluciÃ³n a esta inversiÃ³n.

---

# 4. Modelo Temporal: Del Sprint al Flujo Continuo

> *"Regularly imposed external deadlines are more effective for delivering completed work."*
> â€” Allan Kelly, Xanpan (citando Buehler, Griffin, Peetz)

Kelly tiene razÃ³n: los humanos necesitan ritmo. Los agentes no, pero **los humanos que gobiernan el proceso SÃ.** La cadencia no desaparece; se transforma. Y se comprime brutalmente.

## 4.1 Tres escalas temporales simultÃ¡neas

El modelo temporal de Xanpan::Agents opera en tres frecuencias:

### Pulso (reemplaza al Sprint): adaptativo

El Pulso **NO** es una iteraciÃ³n de desarrollo. Es una **iteraciÃ³n de gobernanza humana**. Durante el perÃ­odo entre Pulsos, los agentes ejecutan historias continuamente. El Pulso es el momento donde los humanos:

- Revisan entregas y aceptan/rechazan contra criterios de aceptaciÃ³n.
- Re-priorizan backlog basado en aprendizaje.
- Refinan historias pendientes en conversaciones humano-agente.
- Revisan mÃ©tricas del enjambre (coste, calidad, rendimiento).
- Deciden si rotar, escalar o reducir agentes.

**DuraciÃ³n adaptativa:** El Pulso por defecto es 1 semana. Si las mÃ©tricas del enjambre son estables y el acceptance rate es >90%, puede extenderse a 2 semanas. Si hay degradaciÃ³n o lanzamiento crÃ­tico, puede comprimirse a 2-3 dÃ­as. El ritmo se adapta a la realidad, no al revÃ©s. La rigidez del sprint fijo muere definitivamente.

### Ciclo (reemplaza al Trimestre): 4-6 semanas

PerÃ­odo operacional de OKRs. Kelly recomienda OKRs trimestrales; Xanpan::Agents comprime a 4-6 semanas porque la velocidad de ejecuciÃ³n permite iterar sobre objetivos mÃ¡s rÃ¡pidamente. Cada Ciclo comienza con sesiÃ³n de planificaciÃ³n estratÃ©gica donde PO y Operador:

- Revisan OKRs del Ciclo anterior (% KRs logrados, lecciones aprendidas).
- Definen 1-3 Objetivos para el prÃ³ximo Ciclo con Key Results medibles y preferiblemente anÃ¡logos (como Kelly recomienda).
- Derivan Ã©picas necesarias para lograr cada KR.
- Descomponen Ã©picas en historias con soporte de agente-planificador.

### Horizonte (aÃ±o): Continuo

Roadmap estratÃ©gico y OKRs anuales. AlineaciÃ³n con el modelo Continuous Digital de Kelly. El enjambre opera siempre; no hay "fin de proyecto."

## 4.2 AnÃ¡logo > Binario en Key Results

Siguiendo a Kelly: *"Es mÃ¡s efectivo plantear key results como declaraciones anÃ¡logas: alguna cantidad de funcionalidad estÃ¡ hecha."* Esto permite a los agentes entregar progreso parcial valioso en vez de perseguir objetivos todo-o-nada. Un KR anÃ¡logo como "Reducir tiempo de respuesta de 2s a menos de 500ms" permite celebrar llegar a 800ms en camino a 500ms.

## 4.3 La muerte del deadline como fuente de estrÃ©s

Kelly argumenta que los deadlines crean urgencia productiva. Con agentes, los deadlines cambian de naturaleza: ya no son fechas de entrega que generan estrÃ©s en humanos. Son **horizontes de evaluaciÃ³n**: momentos predefinidos donde los humanos evalÃºan progreso contra KRs y deciden si pivotar. La emociÃ³n humana del "vamos a llegar tarde" se transforma en el anÃ¡lisis frÃ­o de "Â¿estÃ¡ la curva de progreso convergiendo al objetivo?"

---

# 5. El Tablero Neural

> *"Each Xanpan team must design its own board. Think of it like Jedi lightsabers: each Jedi must build their own."*
> â€” Allan Kelly, Xanpan

Kelly insiste: si no podemos ver, no podemos aprender. El tablero es el sistema nervioso del equipo. En Xanpan::Agents, el tablero estÃ¡tico de post-its evoluciona a un **dashboard neural en tiempo real** donde cada historia, cada agente, cada mÃ©trica respira en vivo.

## 5.1 Columnas del flujo

| Columna | DescripciÃ³n | Velocidad tÃ­pica |
|---|---|---|
| **Backlog** | Historias priorizadas por valor de negocio, alimentadas por PO y backlog predictivo | Continua |
| **Refinamiento** | ConversaciÃ³n humano-agente activa para clarificar criterios | Minutos |
| **Agent:Working** | Historia en ejecuciÃ³n activa por agentes. WIP controlado. | Minutos a horas |
| **Agent:Review** | Entregable completado, pasando eval automÃ¡tico (tests, lint, evals) | Segundos a minutos |
| **Human:Approval** | PasÃ³ eval automÃ¡tico, espera aceptaciÃ³n del PO | Horas (Pulso) |
| **Done** | Aceptada y desplegada o lista para despliegue | Terminal |
| **Rejected** | Rechazada por PO o fallÃ³ eval. Retorna a Refinamiento con feedback. | Retroceso |
| **Unplanned** | Trabajo emergente: bugs, urgencias. Kelly acepta que es inevitable y valioso. | Variable |

## 5.2 Tarjetas por color (adaptaciÃ³n Kelly)

- ðŸ”µ **Azul:** Historias de negocio con valor. Escritas por PO.
- ðŸ”´ **Rojo:** Bugs. Los agentes auto-detectan algunos via evals; otros reportados por usuarios.
- ðŸŸ¡ **Amarillo:** Trabajo no planificado. Kelly acepta que es inevitable e incluso valioso.
- ðŸŸ¢ **Verde:** Mejoras de proceso: refactoring, optimizaciÃ³n de prompts, mejoras de evals.
- ðŸŸ  **Naranja (NUEVO):** CalibraciÃ³n del enjambre: actualizaciones de modelo, re-indexaciÃ³n de embeddings, ajustes de context engineering. Trabajo que no existÃ­a en equipos humanos.
- ðŸŸ£ **PÃºrpura (NUEVO v2.0):** Tareas auto-propuestas por el enjambre. El enjambre auto-evolutivo genera tarjetas pÃºrpura cuando detecta oportunidades de mejora. Requieren aprobaciÃ³n del Operador.

## 5.3 LÃ­mites WIP para agentes

Kelly limita el WIP humano: "default una tarea por persona." Los agentes pueden ejecutar en paralelo, pero el WIP sigue importando por dos razones: **Coste** (cada agente ejecutando consume tokens; mÃ¡s paralelismo = mÃ¡s coste instantÃ¡neo) y **Coherencia** (demasiados agentes modificando el mismo codebase simultÃ¡neamente generan conflictos de merge). El lÃ­mite WIP es ahora una **restricciÃ³n de coherencia, no de capacidad cognitiva**. El Operador configura lÃ­mites WIP por zona del codebase, no por agente individual.

---

# 6. EconomÃ­a de Tokens: De Story Points a MÃ©tricas Reales

> *"'Actuals' are nothing more than another estimate. A retrospective estimate."*
> â€” Allan Kelly, Xanpan

Kelly dedica capÃ­tulos enteros a demoler la ilusiÃ³n de la estimaciÃ³n precisa en equipos humanos: planning fallacy, Ley de Hofstadter, inutilidad de los "actuals." Con agentes, el problema de la estimaciÃ³n se transforma completamente. Los agentes no sufren planning fallacy. No tienen ego que infle o desinfle estimaciones. Pero introducen una nueva variable: el coste de inferencia.

## 6.1 Tres mÃ©tricas que reemplazan la velocidad

| MÃ©trica | DefiniciÃ³n | AnÃ¡logo clÃ¡sico |
|---|---|---|
| **Coste por Historia (CpH)** | Tokens consumidos por historia completada y aceptada | Velocidad (puntos/sprint) |
| **Tasa de AceptaciÃ³n (TA)** | % de historias aceptadas por PO al primer intento | Calidad (defectos) |
| **Cycle Time** | Tiempo desde Backlog hasta Done para una historia | Lead time |

## 6.2 PriorizaciÃ³n por valor, no por esfuerzo

Kelly recomienda priorizar por valor de negocio. En Xanpan::Agents esto se **radicaliza**: dado que el "esfuerzo" ya no es recurso humano escaso sino gasto econÃ³mico predecible (tokens), la priorizaciÃ³n se simplifica:

> **FÃ“RMULA DE PRIORIDAD**
>
> `Prioridad = Valor de Negocio / (Coste Estimado en Tokens Ã— Multiplicador de Riesgo)`
>
> Donde el Multiplicador de Riesgo aumenta para historias clasificadas como "destructivas" o con alta probabilidad de alucinaciÃ³n. Esto es priorizaciÃ³n pura por ROI: cuÃ¡nto valor por token invertido.

## 6.3 Presupuesto de tokens por Ciclo

Cada Ciclo tiene un presupuesto de tokens aprobado. El Operador distribuye el presupuesto entre: historias de negocio (**60-70%**), BAU y bugs (**20-25%**), y calibraciÃ³n del enjambre (**10-15%**). Siguiendo el principio de Kelly: *"watching the numbers"* sin perseguirlos como targets (evitando la Ley de Goodhart).

## 6.4 La curva de coste decreciente

**Esto es exponencialidad real:** los modelos se abaratan un ~40% cada 6 meses. GPT-4 costÃ³ $60/M tokens en 2023. GPT-4.1 cuesta $2/M tokens en 2025. Mismo rendimiento, 30x mÃ¡s barato. Esto significa que la capacidad del enjambre **crece exponencialmente a presupuesto constante**. Una metodologÃ­a diseÃ±ada para esta curva debe ser agresiva en adopciÃ³n hoy, sabiendo que el ROI se amplifica con el tiempo.

**Nota de prudencia (v2.1):** Esta curva es una hipÃ³tesis de trabajo basada en datos observados 2023-2026, no un axioma garantizado. Las scaling laws muestran indicios de rendimientos decrecientes en ciertos benchmarks. La metodologÃ­a incluye un modo degradado explÃ­cito (ver Â§15.5) para el escenario donde la curva se aplana.

---

# 7. Calidad: El Escudo contra la AlucinaciÃ³n

> *"Unless a team is actively working to improve software quality, not only will Xanpan fail, but any attempts at Agile will also fail."*
> â€” Allan Kelly, Xanpan

Kelly es intransigente: la calidad no es opcional. TDD, ATDD, refactoring, CI, code reviews son obligatorios. En Xanpan::Agents, las prÃ¡cticas tÃ©cnicas se transforman y se amplifican.

## 7.1 Mapeo de prÃ¡cticas tÃ©cnicas

| PrÃ¡ctica Kelly | TransformaciÃ³n en Xanpan::Agents | Intensidad |
|---|---|---|
| **TDD** | Nativa: el agente genera tests y cÃ³digo simultÃ¡neamente. Eval pipeline verifica cobertura mÃ­nima. | â˜…â˜…â˜… |
| **ATDD** | PO escribe ACs, agente genera tests de aceptaciÃ³n. Tests ejecutados pre-aprobaciÃ³n humana. | â˜…â˜…â˜… |
| **Refactoring** | Agentes refactorizan continuamente como tareas verdes. MÃ©tricas de complejidad ciclomÃ¡tica monitoreadas. | â˜…â˜…â˜… |
| **CI** | Cada historia genera PR con CI automÃ¡tico: lint + tests + evals. | â˜…â˜…â˜… |
| **Code Review** | Eval automÃ¡tico + cross-review entre agentes. Reviewer-agent distinto de author-agent. | â˜…â˜…â˜… |
| **Pair Programming** | COLAPSA. Reemplazado por cross-eval. Los agentes no necesitan socializar conocimiento. | N/A |
| **Coding Standards** | Context engineering: CONVENTIONS.md como ley. Linting automÃ¡tico pre-merge. | â˜…â˜…â˜… |
| **Static Analysis** | Nativo en pipeline CI. Ruff, ESLint, type checking. | â˜…â˜…â˜… |

## 7.2 Evals: La prÃ¡ctica tÃ©cnica obligatoria de esta era

**Los Evals son a Xanpan::Agents lo que TDD es al Xanpan clÃ¡sico:** la prÃ¡ctica tÃ©cnica obligatoria sin la cual todo fracasa.

- **Eval de regresiÃ³n:** Dataset curado de queries + respuestas esperadas por agente. Ejecutado en cada cambio de modelo o config.
- **Eval de alucinaciÃ³n:** VerificaciÃ³n de que el output del agente no contiene informaciÃ³n fabricada.
- **Eval de tool-calling:** VerificaciÃ³n de que el agente selecciona herramientas correctas para cada tarea.
- **Eval de coste:** VerificaciÃ³n de que el consumo de tokens estÃ¡ dentro de lÃ­mites presupuestarios.
- **Eval de seguridad:** VerificaciÃ³n de que el agente no expone datos sensibles, no escala privilegios, no realiza acciones fuera de su allowlist. Alineado con el pilar de seguridad de HCAI.

## 7.3 Definition of Done para agentes

Kelly define DoD como contrato de completitud. En Xanpan::Agents, el DoD se formaliza como pipeline que toda historia debe pasar:

1. CÃ³digo generado con unit tests (cobertura > umbral configurado).
2. Tests de aceptaciÃ³n derivados de ACs pasan.
3. Lint y type checking pasan sin errores.
4. Eval de regresiÃ³n pasa (no rompe funcionalidad existente).
5. Eval de seguridad pasa (no expone datos, no escala privilegios).
6. PR creado con descripciÃ³n clara y contexto.
7. CI verde.
8. AprobaciÃ³n humana del PO contra criterios de aceptaciÃ³n.

> ðŸ”’ **GOBERNANZA HCAI: FIABILIDAD + SEGURIDAD + CONFIANZA**
>
> Shneiderman define tres pilares de gobernanza: fiabilidad (prÃ¡cticas de ingenierÃ­a rigurosas), cultura de seguridad (gestiÃ³n organizacional), certificaciÃ³n de confianza (auditorÃ­a externa). En Xanpan::Agents: Fiabilidad = evals + CI/CD. Cultura de seguridad = context engineering + principio de mÃ­nimo privilegio. Confianza = transparencia total via dashboard + audit trail de cada acciÃ³n del agente.

---

# 8. OKRs: Gobernanza EstratÃ©gica del Enjambre

> *"Writing quarterly OKRs is fundamentally a strategy question: what are the strategic priorities for the next quarter?"*
> â€” Allan Kelly, OKRs in Agile

Los OKRs son el mecanismo que conecta la estrategia de negocio con la ejecuciÃ³n del enjambre. Kelly describe cÃ³mo los OKRs resuelven tres problemas: orientaciÃ³n, autonomÃ­a y organizaciÃ³n.

## 8.1 OKR-first, no Backlog-first

Kelly presenta dos modelos: backlog-first (historias generan OKRs) y OKR-first (OKRs generan historias). Xanpan::Agents adopta categÃ³ricamente **OKR-first:**

1. **OKRs de Ciclo** definen Objetivos y Key Results.
2. **De cada KR** se derivan Ã‰picas necesarias.
3. **De cada Ã‰pica** se derivan Historias.
4. **Historias** pueblan backlog.
5. **Agentes** consumen backlog en orden de prioridad por valor.

El flujo es **unidireccional y trazable**: Estrategia â†’ OKR â†’ KR â†’ Ã‰pica â†’ Historia â†’ Criterios de AceptaciÃ³n â†’ EjecuciÃ³n â†’ Eval â†’ AprobaciÃ³n Humana.

## 8.2 Estructura OKR en Xanpan::Agents

| Componente | DescripciÃ³n | Responsable |
|---|---|---|
| **Objetivo** | Cualitativo, inspiracional, alineado al Higher Purpose de Kelly. | PO |
| **Key Results (2-4)** | Cuantitativos, anÃ¡logos (no binarios), medibles. | PO |
| **Ã‰picas derivadas** | Trabajo necesario para lograr KRs. Descompuesto con soporte de agente-planificador. | PO + Agente |
| **Presupuesto de tokens** | Presupuesto de inferencia estimado para el Ciclo. | Operador |
| **Criterios de eval** | CÃ³mo se medirÃ¡ el Ã©xito del KR al final del Ciclo. | PO + Operador |

## 8.3 BAU: Mantener las luces encendidas

Kelly dedica un capÃ­tulo entero al trabajo BAU (Business As Usual) y ofrece cuatro opciones. Xanpan::Agents adopta la **OpciÃ³n 4 de Kelly: hacer BAU un Objetivo cero explÃ­cito**. Reservar porcentaje fijo del presupuesto de tokens del Ciclo (tÃ­picamente 20-30%) para trabajo BAU: bugs, soporte, deuda tÃ©cnica, mantenimiento.

## 8.4 OKRs asistidos por agentes

**AquÃ­ rompemos otro lÃ­mite:** en niveles de madurez 4-5 del HCAI-MM, los agentes no solo ejecutan hacia OKRs sino que **proponen OKRs**. Un agente-analista con acceso a mÃ©tricas de producto, datos de uso, y OKRs histÃ³ricos puede generar borradores de Objetivos y Key Results para el prÃ³ximo Ciclo. El PO revisa, ajusta y aprueba. La inteligencia estratÃ©gica es hÃ­brida: datos de mÃ¡quina + juicio humano.

Esto es **inteligencia hÃ­brida** en su forma mÃ¡s pura (concepto HCAI): ni la mÃ¡quina sola ni el humano solo producen mejores OKRs que ambos juntos. La mÃ¡quina ve patrones en datos que el humano no detecta. El humano aporta visiÃ³n, valores y conocimiento del mercado que la mÃ¡quina no tiene.

---

# 9. Arquitectura del Enjambre Auto-Evolutivo

Esta secciÃ³n no tiene equivalente en Kelly porque los equipos humanos no necesitan ser "configurados." Los agentes SÃ. El Operador diseÃ±a la topologÃ­a del enjambre.

## 9.1 Roles de agentes

| Rol | FunciÃ³n | Tier de modelo | Ejemplo |
|---|---|---|---|
| **Planner** | Descompone Ã©picas en historias y historias en tareas | Tier 3 (Frontier) | Opus, GPT-4.5, Gemini Ultra |
| **Coder** | Implementa cÃ³digo desde historias con TDD | Tier 2-3 | Sonnet, GPT-4.1, Gemini Pro |
| **Reviewer** | Revisa PRs generados por Coders; cross-eval | Tier 2 | Sonnet, GPT-4.1 |
| **Tester** | Genera y ejecuta tests de aceptaciÃ³n e integraciÃ³n | Tier 2 | Sonnet, Gemini Pro |
| **Refactorer** | Mejora continua de cÃ³digo existente (tareas verdes) | Tier 2 | Sonnet, GPT-4.1 |
| **Analyst** | Genera mÃ©tricas, resÃºmenes, reportes para PO | Tier 1-2 | Haiku, Flash, Mini |
| **Orchestrator** | Coordina flujo entre agentes; Model Router | Tier 1 | Haiku, Flash |
| **Sentinel** | Meta-agente que monitorea al enjambre (ver Â§9.4) | Tier 2-3 | Sonnet, Opus |

## 9.2 Conway Invertido

Kelly cita la Ley de Conway: la estructura del equipo determina la estructura del software. En Xanpan::Agents, **invertimos**: la estructura del software dicta la topologÃ­a del enjambre. Cada Ã¡rea del codebase (frontend, backend, infra) puede tener agentes especializados con context engineering dedicado. Los lÃ­mites WIP aplican por zona, no por agente. El Operador puede reconfigurar topologÃ­a entre Ciclos sin coste de "forming-storming" (los agentes no tienen curva de Tuckman).

## 9.3 Model Router

Cada tarea se enruta al modelo Ã³ptimo por coste/capacidad:

| Tier | Modelos | Casos de uso | Coste relativo |
|---|---|---|---|
| **Tier 1 (EconÃ³mico)** | Flash, Haiku, Mini | ClasificaciÃ³n, formateo, anÃ¡lisis simple, orquestaciÃ³n | $ |
| **Tier 2 (Balance)** | Sonnet, GPT-4.1, Gemini Pro | Tool-calling, generaciÃ³n de cÃ³digo estÃ¡ndar, reviews | $$ |
| **Tier 3 (Frontier)** | Opus, GPT-4.5, Gemini Ultra | Razonamiento complejo, planificaciÃ³n, decisiones arquitectÃ³nicas | $$$ |
| **Tier 4 (Reasoning)** | o3, modelos thinking | Problemas matemÃ¡ticos, lÃ³gicos, evaluaciÃ³n crÃ­tica | $$$$ |

## 9.4 El enjambre auto-evolutivo

**AquÃ­ entramos en territorio verdaderamente nuevo.** El enjambre no solo ejecuta: **aprende y se optimiza:**

- **Auto-optimizaciÃ³n de prompts:** El Sentinel analiza patrones de rechazo y propone ajustes a system prompts de otros agentes. El Operador aprueba los cambios.
- **Auto-generaciÃ³n de evals:** Cuando una historia es rechazada, el Sentinel genera automÃ¡ticamente un nuevo caso de eval para prevenir la recurrencia. El nuevo eval se agrega al pipeline tras aprobaciÃ³n del Operador.
- **Auto-reconfiguraciÃ³n de topologÃ­a:** Si el Sentinel detecta que un Ã¡rea del codebase tiene cycle time consistentemente alto, propone agregar un agente especializado o cambiar de tier de modelo. El Operador decide.
- **Tarjetas pÃºrpura:** El Sentinel genera tarjetas pÃºrpura en el tablero con propuestas de mejora. Son visibles para PO y Operador pero no se ejecutan sin aprobaciÃ³n humana. HCAI en acciÃ³n: automatizaciÃ³n alta + control humano alto.

### Quis custodiet ipsos custodes? El eval del Sentinel

El Sentinel es un agente. Puede alucinar. Puede tener bias en sus anÃ¡lisis de calidad. Si el Sentinel propone una reconfiguraciÃ³n basada en una evaluaciÃ³n errÃ³nea, el error se propaga sistÃ©micamente. SoluciÃ³n: **separaciÃ³n de concerns estilo auditor externo.**

1. **Sentinel â‰  Reviewer:** El Sentinel nunca revisa las mismas historias que evalÃºa. Su input son mÃ©tricas agregadas (tasas, tendencias, anomalÃ­as), no PRs individuales.
2. **Eval del evaluador:** Un subset de las propuestas del Sentinel se evalÃºa retroactivamente: Â¿las propuestas aplicadas mejoraron realmente las mÃ©tricas? Si la tasa de mejora efectiva del Sentinel cae por debajo de un umbral, alerta al Operador.
3. **Modelo diferente:** El Sentinel usa un modelo y provider diferente al enjambre que evalÃºa. Si el enjambre usa Claude, el Sentinel usa GPT (o viceversa). Diversidad de modelos como defensa contra bias compartido.
4. **Veto asimÃ©trico:** El Sentinel puede proponer cualquier cosa pero no puede ejecutar nada. El humano tiene veto absoluto y sin justificaciÃ³n requerida. La asimetrÃ­a es intencional: proponer es barato, ejecutar errores es caro.

> âš¡ **PRINCIPIO DE AUTO-EVOLUCIÃ“N GOBERNADA**
>
> El enjambre puede proponer cualquier cambio sobre sÃ­ mismo: prompts, evals, topologÃ­a, modelos. Pero no puede ejecutar ningÃºn cambio sin aprobaciÃ³n humana. Es el patrÃ³n HCAI de "high automation + high control" llevado al meta-nivel: el sistema se auto-mejora pero los humanos gobiernan la direcciÃ³n de la mejora.

## 9.5 Equipos Ameba con agentes

Kelly adopta el modelo de "Equipos Ameba" de Inamori: equipos pequeÃ±os que crecen, se dividen y contraen orgÃ¡nicamente. Con agentes, la elasticidad es **instantÃ¡nea:**

- **Â¿Necesitas mÃ¡s capacidad para un deadline?** Escala el nÃºmero de agentes-coder en minutos.
- **Â¿El trabajo se reduce?** Desescala sin coste emocional. No hay despidos, no hay pÃ©rdida de moral.
- **Â¿Ãrea nueva de producto?** Spawn sub-enjambre con context engineering especÃ­fico.
- **Â¿Merge de dos lÃ­neas de producto?** Fusiona context engineering. Los agentes no tienen territorios polÃ­ticos.

---

# 10. Human-in-the-Loop: Los Cuatro Loops de Gobernanza HCAI

> *"The human-in/on-the-loop HCAI design paradigm encompasses the entire lifecycle of a human-AI system."*
> â€” Wei Xu, HCAI-MF

Xu no describe solo "poner un botÃ³n de aprobaciÃ³n." Describe un paradigma donde el loop humano **abarca el ciclo de vida completo** del sistema: requisitos, diseÃ±o, desarrollo, despliegue, uso, operaciones y gobernanza.

## 10.1 Loop 1: Human-in-the-Loop (Individuo-Agente)

### Intervenciones obligatorias

- **AceptaciÃ³n de historias:** PO acepta o rechaza cada historia completada contra criterios de aceptaciÃ³n. Sin auto-aprobaciÃ³n. Nunca.
- **Acciones destructivas:** Cualquier operaciÃ³n clasificada como "destructiva" requiere aprobaciÃ³n explÃ­cita del Operador.
- **Cambios arquitectÃ³nicos:** Decisiones que afectan estructura fundamental del sistema.
- **Actualizaciones de modelo:** Cambiar modelo base requiere regresiÃ³n + aprobaciÃ³n.
- **Cambios auto-evolutivos:** Toda propuesta del Sentinel requiere aprobaciÃ³n del Operador.

### AutonomÃ­a del enjambre (todo lo NO listado arriba)

- DescomposiciÃ³n de historias en tareas.
- GeneraciÃ³n de cÃ³digo y tests.
- EjecuciÃ³n de CI/CD hasta staging.
- Refactoring continuo (tareas verdes).
- GeneraciÃ³n de PRs y documentaciÃ³n.
- Eval automÃ¡tico entre agentes (reviewer â‰  coder).
- Deploy a producciÃ³n con feature flags (si evals robustos y rollback automÃ¡tico configurado).

## 10.2 Loop 2: Organization-in-the-Loop

Herrmann & Pfeiffer (2023) enfatizan que HCAI no puede ignorar el contexto organizacional. En Xanpan::Agents:

- **OKRs como alineaciÃ³n organizacional:** Los OKRs del enjambre derivan de la estrategia de la organizaciÃ³n. No son autÃ³nomos.
- **Presupuesto de tokens aprobado por liderazgo:** El coste del enjambre es gasto operativo aprobado a nivel organizacional.
- **Cultura de calidad como norma:** La organizaciÃ³n define estÃ¡ndares de calidad que se implementan via context engineering y evals.
- **RediseÃ±o de trabajo:** La adopciÃ³n de Xanpan::Agents requiere rediseÃ±ar roles, procesos y flujos de decisiÃ³n. No es "agregar agentes al proceso existente." Ver Â§16 para el modelo de transiciÃ³n.

## 10.3 Loop 3: Ecosystem-in-the-Loop

El enjambre no opera en aislamiento. Interopera con otros sistemas:

- **MCP (Model Context Protocol) para interoperabilidad:** Los agentes se conectan con herramientas externas via MCP estÃ¡ndar.
- **CoordinaciÃ³n con otros sistemas IA:** Si la organizaciÃ³n tiene mÃºltiples enjambres o sistemas IA, deben coordinarse.
- **Ecosistema cognitivo distribuido:** Xu describe ecosistemas como "sistemas cognitivos distribuidos donde humanos y IA colectivamente perciben, razonan, aprenden y deciden." El enjambre es un nodo en este ecosistema.

## 10.4 Loop 4: Society-in-the-Loop

El nivel macrosocial de HCAI:

- **Cumplimiento regulatorio:** EU AI Act, NIST AI RMF, ISO/IEC 42001. El enjambre debe operar dentro de marcos regulatorios.
- **Impacto laboral:** Xanpan::Agents no evita la pregunta difÃ­cil: Â¿quÃ© pasa con los desarrolladores humanos? La respuesta HCAI: los humanos se elevan a roles de mayor valor (PO, Operador, arquitectos, estrategas) mientras los agentes absorben trabajo mecÃ¡nico. Ver Â§16 para modelo de transiciÃ³n.
- **Transparencia y auditabilidad:** Cada decisiÃ³n del agente tiene audit trail. Cada historia tiene trazabilidad completa. La organizaciÃ³n puede demostrar responsabilidad.

> ðŸŒ **PRINCIPIO DE MÃNIMA INTERVENCIÃ“N MAXIMAL**
>
> El humano interviene SOLO donde: (a) hay valor de negocio que juzgar (PO), (b) hay riesgo de daÃ±o irreversible (Operador), (c) la calidad del enjambre se degrada mÃ¡s allÃ¡ de umbrales configurados (alertas automÃ¡ticas), o (d) hay implicaciones organizacionales, ecosistÃ©micas o sociales que requieren juicio humano. Todo lo demÃ¡s es autÃ³nomo. Esto no es negligencia; es diseÃ±o. Es HCAI.

---

# 11. Digital Continuo con Agentes: El Software Longevo

> *"Software is an asset for the business that owns it, but it cannot be a static asset. Software ages and degrades because the world around it changes."*
> â€” Allan Kelly, Continuous Digital

Kelly argumenta contra el pensamiento de "proyecto": el software no estÃ¡ "terminado", evoluciona continuamente. Con agentes IA, este argumento se fortalece **exponencialmente.**

## 11.1 Software como activo vivo acelerado

- **InversiÃ³n continua posible y barata:** Los agentes pueden mejorar, refactorizar y actualizar software continuamente a coste marginal. La excusa de "no hay presupuesto para mantenimiento" muere.
- **EliminaciÃ³n de gaps entre "proyectos":** Kelly advierte que los gaps entre proyectos causan pÃ©rdida de conocimiento tÃ¡cito. Con agentes, el context engineering preserva conocimiento explÃ­citamente.
- **Deuda tÃ©cnica como tarea continua:** En vez de acumular deuda hasta que un "proyecto de refactoring" la aborde, agentes-refactorer trabajan continuamente como tareas verdes.

## 11.2 El software longevo

Si los agentes pueden mantener, actualizar y evolucionar software continuamente a coste marginal, el concepto de "end of life" del software cambia fundamentalmente. Los agentes pueden migrar frameworks, actualizar dependencias, refactorizar arquitecturas completasâ€”todo como flujo continuo de tareas verdes. El software se vuelve significativamente mÃ¡s **longevo** mientras haya valor de negocio que justifique su existencia.

**Matiz necesario:** El software no es literalmente inmortal. Muere no solo por pÃ©rdida de valor de negocioâ€”muere por muerte de ecosistema:

- **APIs que se deprecan** sin reemplazo equivalente.
- **EstÃ¡ndares que cambian** de forma incompatible (IPv4 â†’ IPv6, HTTP/1.1 â†’ HTTP/3).
- **Regulaciones que invalidan arquitecturas enteras** (GDPR hizo morir sistemas completos cuya arquitectura no permitÃ­a "derecho al olvido").
- **Plataformas que desaparecen** (Flash, Windows Phone, APIs de Twitter pre-Musk).

Los agentes pueden migrar frameworks, sÃ­, pero no pueden evitar la obsolescencia regulatoria o ecosistÃ©mica. Lo que pueden hacer es **detectar temprano** el drift ecosistÃ©mico (via Sentinel monitoreando changelogs de dependencias, anuncios de deprecaciÃ³n, cambios regulatorios) y **proponer migraciÃ³n proactiva** antes de que sea crisis.

## 11.3 Productos, no proyectos: amplificado

Kelly insiste: piensa en productos, no en proyectos. Con agentes:

- **No hay "fin de proyecto":** el enjambre opera siempre.
- **No hay "equipo de mantenimiento" separado:** el mismo enjambre que construye, mantiene.
- **No hay "hand-off":** no hay transferencia de conocimiento porque el conocimiento estÃ¡ en el context engineering, no en cerebros humanos que se van.
- **El presupuesto es continuo:** tokens/mes, no "presupuesto de proyecto."

---

# 12. Observabilidad y Retrospectiva AnalÃ­tica

## 12.1 Dashboard del enjambre

El Operador monitorea un dashboard en tiempo real con cinco dimensiones:

| DimensiÃ³n | MÃ©tricas | Frecuencia |
|---|---|---|
| **Coste** | Tokens/Pulso, Coste/Historia, Coste/KR, % presupuesto consumido | Continua |
| **Calidad** | Tasa de AceptaciÃ³n, Tasa de AlucinaciÃ³n, Cobertura de Tests, Scores de Eval | Por Pulso |
| **Velocidad** | Historias Done/Pulso, Cycle Time promedio, Throughput | Por Pulso |
| **Modelo** | Tasa de Ã©xito por modelo, latencia promedio, frecuencia de fallback | Continua |
| **Enjambre** | UtilizaciÃ³n de agentes, WIP por zona, profundidad de cola, tarjetas pÃºrpura pendientes | Continua |

## 12.2 Retrospectiva AnalÃ­tica

Al final de cada Ciclo (no cada Pulso), PO y Operador conducen la **Retrospectiva AnalÃ­tica:**

1. **RevisiÃ³n de OKRs:** Â¿QuÃ© KRs se lograron? Â¿CuÃ¡les no y por quÃ©?
2. **AnÃ¡lisis de coste:** Â¿Se respetÃ³ el presupuesto de tokens? Â¿DÃ³nde se concentrÃ³ el gasto?
3. **AnÃ¡lisis de calidad:** Â¿QuÃ© patrones de rechazo se observaron? Â¿Hay alucinaciones recurrentes?
4. **Decisiones de ajuste:** Â¿Cambiar modelos? Â¿Ajustar context engineering? Â¿Reconfigurar topologÃ­a?
5. **ActualizaciÃ³n de evals:** Agregar nuevos casos de test basados en fallos observados.
6. **RevisiÃ³n de tarjetas pÃºrpura:** Evaluar propuestas auto-evolutivas del Sentinel pendientes.
7. **Eval del Sentinel:** Â¿Las propuestas del Sentinel aplicadas en el Ciclo anterior mejoraron mÃ©tricas? Â¿La tasa de mejora efectiva es aceptable?

**Sin resentimiento, sin polÃ­tica:** La retrospectiva analÃ­tica elimina la dimensiÃ³n emocional de la retro clÃ¡sica. No hay "Â¿quÃ© saliÃ³ mal?" con carga emocional. Hay datos, patrones y decisiones operacionales. La polÃ­tica de equipo desaparece como variable.

---

# 13. Seguridad y Gobernanza Multi-Nivel

## 13.1 Principio de mÃ­nimo privilegio por agente

- **Allowlist explÃ­cito:** Cada agente tiene allowlist explÃ­cito de herramientas (AgentSkills) que puede invocar.
- **Sin acceso directo a secretos de producciÃ³n:** Secretos inyectados en runtime por pipeline CI/CD.
- **SeparaciÃ³n de privilegios:** Agentes-coder no pueden desplegar a producciÃ³n; solo el pipeline CI/CD puede, tras aprobaciÃ³n humana.

## 13.2 Aislamiento de ejecuciÃ³n

| Nivel | Tipo | DescripciÃ³n |
|---|---|---|
| **Nivel 1 (Read)** | Container read-only | Para queries y anÃ¡lisis. Sin escritura. |
| **Nivel 2 (Write)** | Container efÃ­mero | Destruido post-ejecuciÃ³n. Para generaciÃ³n de cÃ³digo. |
| **Nivel 3 (OS Shell)** | MicroVM (Firecracker) | Timeout estricto, sin red externa. Para ejecuciÃ³n de tests. |

## 13.3 Agent-to-agent prompt injection

Una amenaza especÃ­fica de los enjambres multi-agente que no existe en sistemas de agente Ãºnico. Cuando los agentes pasan datos entre sÃ­ (el coder pasa cÃ³digo al reviewer, el analyst pasa datos al synthesizer), un agente comprometido por prompt injection vÃ­a input de usuario puede inyectar instrucciones maliciosas en su output, que otro agente consumirÃ¡ como input legÃ­timo.

**Controles:**

- **SanitizaciÃ³n en cada interfaz interna.** El output de cada agente se valida contra un schema tipado antes de alimentar al siguiente agente. No se pasa texto libre entre agentes si se puede evitar; se pasan estructuras tipadas.
- **Context isolation.** Cada agente tiene su propio contexto. El agente-reviewer no hereda el prompt del agente-coder; recibe solo el artefacto (cÃ³digo) y su propio prompt de revisiÃ³n. Las instrucciones inyectadas en el output del coder quedan aisladas como datos, no como instrucciones.
- **DetecciÃ³n de anomalÃ­as inter-agente.** El agente-observer (Swarm::Ops Â§7.2) monitorea patrones de comunicaciÃ³n entre agentes. Un agente que de repente produce outputs con estructura inusual o con contenido que parece instruccional (meta-prompts) es seÃ±alizado.
- **Diversidad de modelos como mitigaciÃ³n.** Si el agente-coder es comprometido vÃ­a un blind spot del modelo que usa, el agente-reviewer (con modelo diferente, Â§9.3) tiene mayor probabilidad de detectar la anomalÃ­a.

## 13.4 Gobernanza multinivel HCAI

Shneiderman propone cuatro niveles de gobernanza. Mapeados a Xanpan::Agents:

| Nivel Shneiderman | Mecanismo en Xanpan::Agents |
|---|---|
| **Equipo: prÃ¡cticas de ingenierÃ­a** | Evals, CI/CD, context engineering, DoD como pipeline automÃ¡tico |
| **OrganizaciÃ³n: cultura de seguridad** | OKRs, presupuesto aprobado, roles definidos (PO/Operador), retrospectiva analÃ­tica |
| **Industria: certificaciÃ³n de confianza** | Audit trail completo, trazabilidad historiaâ†’cÃ³digoâ†’deploy, cumplimiento de estÃ¡ndares |
| **Gobierno: regulaciÃ³n** | Compliance con EU AI Act, NIST AI RMF, ISO/IEC 42001, reportes de incidentes |

---

# 14. Velocidad Exponencial: El Meta-Principio

**Esta secciÃ³n no existe en ninguna metodologÃ­a Ã¡gil.** Ninguna. Porque ninguna metodologÃ­a fue diseÃ±ada para un mundo donde la capacidad del ejecutor se duplica cada seis meses. Xanpan::Agents sÃ­.

## 14.1 La curva exponencial: hipÃ³tesis de trabajo

Los datos observados 2023-2026 son inequÃ­vocos:

- **Coste de inferencia:** Cae ~40% cada 6 meses. GPT-4 costÃ³ $60/M tokens en 2023. GPT-4.1 cuesta $2/M tokens en 2025. Mismo rendimiento, 30x mÃ¡s barato.
- **Capacidad de los modelos:** Cada generaciÃ³n maneja mÃ¡s contexto, comete menos errores, usa herramientas mejor. Ventana de 200K tokens hoy; 1M+ maÃ±ana.
- **Herramientas de agentes:** MCP, Claude Code, Codex CLI, agentes de navegaciÃ³n, agentes de investigaciÃ³n: cada trimestre aparecen capacidades nuevas.

**Nota crÃ­tica (v2.1):** Estos datos son observaciones empÃ­ricas, no leyes de la fÃ­sica. Las scaling laws muestran indicios de rendimientos decrecientes en ciertos benchmarks desde mid-2025. La exponencialidad es nuestra **hipÃ³tesis de trabajo**, no un axioma. La metodologÃ­a estÃ¡ diseÃ±ada para *surfear* la exponencialidad si continÃºa, y para *degradar gracefully* si se aplana (ver Â§15.5).

**Una metodologÃ­a que no estÃ¡ diseÃ±ada para absorber mejoras exponenciales es una metodologÃ­a que se vuelve obsoleta en meses.** Pero una metodologÃ­a que asume la exponencialidad como garantÃ­a es una metodologÃ­a que colapsa ante la primera meseta.

## 14.2 Principios para velocidad exponencial

### Principio 1: DiseÃ±a para el modelo de maÃ±ana, no el de hoy

La arquitectura del enjambre debe asumir que en 6 meses los modelos serÃ¡n mÃ¡s capaces y mÃ¡s baratos. Esto significa: no optimices en exceso para las limitaciones actuales. Si hoy necesitas un workaround porque el modelo falla en X, pon un eval pero asume que el workaround serÃ¡ temporal.

### Principio 2: Automatiza la automatizaciÃ³n

No es suficiente automatizar el desarrollo. Hay que **automatizar la automatizaciÃ³n misma**. El Sentinel es la primera capa de esto: un agente que optimiza a otros agentes. En niveles de madurez 5, la organizaciÃ³n tiene meta-agentes que optimizan la metodologÃ­a misma: ajustan duraciÃ³n de Pulsos, recalibran presupuestos de tokens, proponen reorganizaciones de topologÃ­aâ€”todo basado en datos.

### Principio 3: Ship fast, eval faster, rollback instantÃ¡neo

El staging clÃ¡sico era necesario porque el despliegue era costoso y el rollback difÃ­cil. Con feature flags, canary deploys y evals robustos, el flujo se comprime: generar â†’ evaluar â†’ desplegar â†’ monitorear â†’ rollback si falla. Todo automÃ¡tico. Todo en minutos. La red de seguridad no es un ambiente de staging; es un pipeline de evals + rollback automÃ¡tico.

### Principio 4: El backlog es un flujo, no un repositorio

Deja de pensar en el backlog como una lista estÃ¡tica que se prioriza y se consume. Es un flujo continuo: entran historias del PO, entran propuestas del backlog predictivo, salen historias ejecutadas, salen historias descartadas. Es un rÃ­o, no un lago. Optimiza el flujo, no el inventario.

### Principio 5: Cada Ciclo debe ser mÃ¡s eficiente que el anterior

Si el Ciclo 3 no es mÃ¡s eficiente que el Ciclo 2, algo estÃ¡ mal. El enjambre auto-evolutivo, la mejora continua de evals, la optimizaciÃ³n de context engineering y la caÃ­da de costes de inferencia deben producir una **curva de mejora compuesta**. MÃ­delo. Si la curva se aplana, diagnostica y corrige. La estasis es sÃ­ntoma de enfermedadâ€”o seÃ±al de que la hipÃ³tesis exponencial necesita revisiÃ³n (ver Â§15.5).

> âš¡ **EL IMPERATIVO EXPONENCIAL**
>
> Estamos en una revoluciÃ³n global e histÃ³rica. Las organizaciones que adopten metodologÃ­as de desarrollo agente-cÃ©ntricas en 2025-2026 tendrÃ¡n una ventaja compuesta que se amplifica con el tiempo. Las que esperen a que "la tecnologÃ­a madure" estarÃ¡n adoptando en 2028 lo que sus competidores perfeccionaron en 2026. En exponenciales, llegar tarde no es llegar un poco despuÃ©s. Es llegar a un orden de magnitud de distancia.

---

# 15. Modos de Fallo y Circuit Breakers

El documento hasta aquÃ­ describe el happy path con detalle. Pero las metodologÃ­as serias no se miden por cÃ³mo funcionan cuando todo va bien, sino por **cÃ³mo fallan cuando algo sale mal**. Esta secciÃ³n describe modos de fallo anticipados y sus circuit breakers.

## 15.1 AlucinaciÃ³n sistÃ©mica

**Modo de fallo:** El enjambre genera cÃ³digo que pasa todos los evals pero contiene errores semÃ¡nticos sutiles. Los tests pasan porque los tests mismos fueron generados por un agente que compartiÃ³ el mismo error de comprensiÃ³n que el agente que generÃ³ el cÃ³digo. Un eval que evalÃºa contra su propio bias es un eval ciego.

**Circuit breakers:**

- **Diversidad de modelos obligatoria:** Coder y Reviewer deben usar modelos de providers diferentes. Si el Coder usa Claude, el Reviewer usa GPT o Gemini. Los modelos de un mismo provider comparten biases de entrenamiento; la diversidad reduce la probabilidad de bias compartido.
- **Golden dataset humano:** Un subset de evals tiene respuestas correctas escritas por humanos, no generadas por agentes. Estas "anclas humanas" detectan drift sistÃ©mico.
- **AuditorÃ­a de muestra por PO:** AdemÃ¡s de aceptar/rechazar historias, el PO periÃ³dicamente (cada Pulso) inspecciona en profundidad 1-2 historias completadas, incluyendo el cÃ³digo generado, no solo el comportamiento funcional. Es costoso en atenciÃ³n humana pero es el Ãºltimo firewall.

## 15.2 Bias en los evals

**Modo de fallo:** Los evals mismos tienen bias. Por ejemplo, un eval de alucinaciÃ³n que solo chequea afirmaciones factuales pero no detecta omisiones crÃ­ticas. O un eval de seguridad que cubre OWASP Top 10 pero no detecta vulnerabilidades novedosas que ningÃºn eval cubre.

**Circuit breakers:**

- **Meta-eval periÃ³dico:** Cada Ciclo, el Operador (asistido por Sentinel) revisa el conjunto de evals: Â¿cubren los modos de fallo observados? Â¿Hay Ã¡reas sin cobertura? El meta-eval es humano-liderado porque la definiciÃ³n de "Â¿quÃ© deberÃ­a evaluar?" requiere juicio que los agentes no tienen.
- **Evals adversariales:** PeriÃ³dicamente, un agente recibe la instrucciÃ³n explÃ­cita de intentar romper el sistema: generar cÃ³digo que pase evals pero sea incorrecto, encontrar formas de escalar privilegios, producir output que engaÃ±e al Reviewer. Los resultados alimentan nuevos evals. Es red-teaming continuo.
- **Incidentes como evals:** Cada bug en producciÃ³n, cada historia rechazada, cada anomalÃ­a detectada se convierte en un nuevo caso de eval. El corpus de evals es un organismo vivo que crece con cada fallo. Kelly: "Quality is free"â€”pero solo si aprendes de cada error.

## 15.3 Divergencia PO-Operador

**Modo de fallo:** El PO quiere velocidad de features. El Operador quiere estabilidad del enjambre. Sus incentivos divergen. El PO presiona por mÃ¡s historias; el Operador frena por degradaciÃ³n de mÃ©tricas. Sin mecanismo de resoluciÃ³n, se genera un deadlock o uno anula al otro.

**Circuit breakers:**

- **OKRs como contrato compartido:** Los OKRs del Ciclo son definidos conjuntamente. Si el PO quiere velocidad, debe explicitarlo como KR medible. Si el Operador quiere estabilidad, debe explicitarlo como KR medible. Ambos firman los mismos OKRs.
- **Dashboard como fuente de verdad:** Las mÃ©tricas no mienten. Si el acceptance rate cae al 60%, el PO no puede argumentar que "todo va bien." Si el coste por historia es 3x el presupuesto, el Operador no puede argumentar que "el enjambre funciona." Los datos resuelven disputas.
- **EscalaciÃ³n a liderazgo:** Si PO y Operador no resuelven, el conflicto escala al nivel Organization-in-the-Loop: el liderazgo decide prioridades basado en estrategia organizacional. Esto deberÃ­a ser raro; si ocurre frecuentemente, la separaciÃ³n de roles puede necesitar rediseÃ±o.

## 15.4 Vulnerabilidad novel no cubierta por evals

**Modo de fallo:** Un agente-coder genera cÃ³digo que introduce una vulnerabilidad de seguridad completamente nuevaâ€”algo que ningÃºn eval cubre porque es un patrÃ³n de ataque que no existÃ­a cuando los evals fueron diseÃ±ados. Pasa CI, pasa evals, pasa review, llega a producciÃ³n.

**Circuit breakers:**

- **Principio de mÃ­nimo privilegio como backstop:** Incluso si el cÃ³digo tiene una vulnerabilidad, el agente que lo generÃ³ no tiene acceso a producciÃ³n. El deploy pasa por pipeline CI/CD con permisos restringidos. La superficie de ataque se contiene por diseÃ±o.
- **Monitoreo de producciÃ³n separado del enjambre:** La observabilidad de producciÃ³n (APM, WAF, anomaly detection) es sistema independiente, no controlado por los mismos agentes que generaron el cÃ³digo. Si el cÃ³digo desplegado tiene comportamiento anÃ³malo, la detecciÃ³n viene de fuera del enjambre.
- **RotaciÃ³n de Security Analyst como rol satÃ©lite:** PeriÃ³dicamente (cada Ciclo o ante cambios significativos de superficie de ataque), un humano especialista en seguridad revisa la arquitectura y los patrones de cÃ³digo desplegados. No revisa cada lÃ­nea; revisa la postura de seguridad del sistema.

## 15.5 Meseta de capacidad (la exponencialidad se detiene)

**Modo de fallo:** Las scaling laws se aplanan. Los modelos dejan de mejorar significativamente entre generaciones. El coste de inferencia se estabiliza. La hipÃ³tesis exponencial del Â§14 deja de ser vÃ¡lida.

**Circuit breakers:**

- **Pulso vuelve a ritmo fijo:** Si la mejora entre Ciclos se aplana (<5% mejora en CpH durante 3 Ciclos consecutivos), el Pulso adaptativo vuelve a frecuencia fija semanal. La incertidumbre requiere mÃ¡s gobernanza, no menos.
- **Presupuesto de tokens como recurso escaso:** Se abandona la mentalidad de "presupuesto creciente a coste constante" y se adopta gestiÃ³n de escasez: priorizaciÃ³n mÃ¡s estricta, eliminaciÃ³n de tareas verdes no esenciales, reducciÃ³n del presupuesto de calibraciÃ³n al mÃ­nimo necesario.
- **Roles humanos se expanden:** Si los agentes no mejoran, los humanos retoman tareas de mayor complejidad cognitiva. El modelo no es binario (humano vs. agente); es un espectro donde la frontera entre "lo que el agente puede" y "lo que el humano debe" se ajusta segÃºn las capacidades reales.
- **InversiÃ³n en evals y context engineering se intensifica:** Si los modelos no mejoran, la forma de sacar mÃ¡s rendimiento es optimizar cÃ³mo los usamos: mejores prompts, mejor contexto, mejores evals. La mejora se desplaza de la capacidad del modelo a la calidad de la ingenierÃ­a del enjambre.

## 15.6 CorrupciÃ³n de context engineering

**Modo de fallo:** Los context files acumulan contradicciones, informaciÃ³n obsoleta o instrucciones ambiguas. Los agentes reciben seÃ±ales conflictivas y su rendimiento se degrada gradualmente sin un fallo discreto que dispare alertas.

**Circuit breakers:**

- **Sentinel como auditor de context (Â§2.2):** VerificaciÃ³n automÃ¡tica de coherencia entre context files y codebase real.
- **Context files en git con blame:** Cada lÃ­nea tiene autor y fecha. El Operador puede trazar cuÃ¡ndo se introdujo una contradicciÃ³n.
- **Metric correlation:** Si el acceptance rate cae sin cambio de modelo ni de tipo de historias, la primera hipÃ³tesis debe ser degradaciÃ³n de context. El dashboard correlaciona cambios en context files con cambios en mÃ©tricas.

---

# 16. Modelo de TransiciÃ³n: Del Equipo Humano al Enjambre

Un CTO leyendo Xanpan::Agents preguntarÃ¡: "Â¿cÃ³mo transiciono mi equipo de 15 devs a esto sin perder 6 meses de productividad?" Esta secciÃ³n ofrece un modelo, no una receta. La transiciÃ³n es un problema abierto y cada organizaciÃ³n tiene restricciones Ãºnicas. Pero hay patrones observados.

## 16.1 La transiciÃ³n NO es un big bang

No se reemplaza un equipo humano por un enjambre de la noche a la maÃ±ana. Se migra gradualmente, exactamente como Kelly recomienda adoptar Xanpan: *"pick'n'mixâ€”toma lo que funcione, descarta lo que no."*

## 16.2 Fases de transiciÃ³n

### Fase 0: Augmented Development (semanas 1-4)

Los desarrolladores humanos **continÃºan haciendo su trabajo normal** pero empiezan a usar agentes como herramientas:

- Cada dev usa un agente-coder como copiloto (Claude Code, Cursor, Copilot).
- Se instrumentan mÃ©tricas bÃ¡sicas: Â¿cuÃ¡nto cÃ³digo genera el agente vs. el humano? Â¿QuÃ© tipo de tareas delegan naturalmente?
- Se identifica al futuro Operador: el dev mÃ¡s interesado en configurar y optimizar agentes.
- Se identifica al futuro PO (o se confirma al PO existente si ya hay uno).

**Objetivo:** Construir intuiciÃ³n sobre quÃ© pueden y no pueden hacer los agentes *en tu codebase especÃ­fico*.

### Fase 1: Parallel Track (semanas 5-12)

Se crea un track paralelo donde un mini-enjambre trabaja en historias seleccionadas mientras el equipo humano continÃºa:

- El Operador (emergente) configura un enjambre mÃ­nimo: 1 Coder + 1 Reviewer + CI con evals bÃ¡sicos.
- Se seleccionan 3-5 historias de bajo riesgo y complejidad media para el enjambre.
- El equipo humano trabaja en el resto del backlog normalmente.
- Se comparan resultados: velocidad, calidad, coste. Sin presiÃ³n por resultados; es un experimento.

**Objetivo:** Validar que el enjambre puede producir cÃ³digo de producciÃ³n en tu stack.

### Fase 2: Accelerated Adoption (semanas 13-24)

El enjambre absorbe progresivamente mÃ¡s tipos de historias:

- Evals se formalizan. Context engineering se establece (CONVENTIONS.md, ARCHITECTURE.md).
- El Operador se dedica full-time (o near full-time) al enjambre.
- Desarrolladores humanos se redistribuyen: algunos se convierten en Operadores de sus propios sub-enjambres, otros migran a roles de PO, arquitectos, o domain experts.
- El tablero se implementa. MÃ©tricas de coste y calidad se rastrean por Pulso.

**Objetivo:** Alcanzar Nivel 2-3 de madurez HCAI.

### Fase 3: Swarm-First (semanas 25+)

El enjambre es el mecanismo primario de ejecuciÃ³n:

- Todas las historias pasan por el enjambre. Humanos intervienen en aceptaciÃ³n, arquitectura, dominio.
- Sentinel activado. Backlog predictivo en prueba. Tarjetas pÃºrpura aparecen.
- Roles humanos estabilizados: PO, Operador, roles satÃ©lite segÃºn necesidad.
- Retrospectiva AnalÃ­tica como prÃ¡ctica establecida.

**Objetivo:** OperaciÃ³n normal segÃºn Xanpan::Agents completo.

## 16.3 Â¿QuÃ© pasa con los desarrolladores humanos?

La pregunta difÃ­cil que esta metodologÃ­a no puede esquivar. Respuesta honesta:

- **Algunos se convierten en Operadores:** Los devs con interÃ©s en infraestructura, DevOps y optimizaciÃ³n son candidatos naturales.
- **Algunos se convierten en POs o domain experts:** Los devs con mÃ¡s conocimiento de negocio y usuarios migran hacia roles de definiciÃ³n de valor.
- **Algunos se convierten en arquitectos:** Los devs senior definen ARCHITECTURE.md, revisan cambios arquitectÃ³nicos, y mantienen la visiÃ³n tÃ©cnica de largo plazo.
- **Algunos se convierten en ingenieros de evals:** DiseÃ±ar, mantener y mejorar el corpus de evals es trabajo especializado que requiere conocimiento profundo del dominio y del stack.
- **Algunos necesitarÃ¡n reubicarse:** Ser honesto sobre esto es parte del principio HCAI de Society-in-the-Loop. La organizaciÃ³n tiene responsabilidad de facilitar la transiciÃ³n: reskilling, reubicaciÃ³n interna, tiempo y soporte.

## 16.4 Anti-patrones de transiciÃ³n

- **"Reemplazamos al equipo el lunes":** Big bang. GarantÃ­a de desastre. Sin context engineering, sin evals, sin comprensiÃ³n de las limitaciones.
- **"Los agentes hacen todo, los devs supervisan":** Subestima la atenciÃ³n requerida. Los devs no estÃ¡n entrenados para supervisar agentes; es una habilidad diferente.
- **"Primero perfeccionamos los evals, despuÃ©s activamos el enjambre":** ParÃ¡lisis por anÃ¡lisis. Los evals se perfeccionan con uso real, no en laboratorio. Ship, eval, iterate.
- **"Mantenemos el Scrum existente y le agregamos agentes":** Los agentes no son "devs mÃ¡s rÃ¡pidos." Son una especie diferente. Intentar meterlos en ceremonias Scrum es como intentar meter un coche de FÃ³rmula 1 en un estacionamiento de centro comercial.

---

# 17. SÃ­ntesis: La MetodologÃ­a Completa

## 17.1 Xanpan::Agents en una oraciÃ³n

**Un Product Owner humano define QUÃ‰ construir via user stories y OKRs. Un Operador humano configura y supervisa un enjambre de agentes IA auto-evolutivo que construye el CÃ“MO. Roles satÃ©lite aportan expertise de dominio cuando se necesita. La calidad se garantiza via evals automÃ¡ticos y aprobaciÃ³n humana. La gobernanza HCAI multi-nivel asegura que la velocidad exponencial sirva a valores humanos. El software evoluciona continuamente como activo longevo. La metodologÃ­a incluye modos de fallo explÃ­citos y circuit breakers para cuando las cosas van mal.**

## 17.2 Tabla de correspondencia Kelly â†’ Xanpan::Agents v2.1

| Concepto clÃ¡sico | TransformaciÃ³n v2.1 | Fundamento |
|---|---|---|
| Sprint (2 semanas) | Pulso adaptativo (3d-2sem) | Velocidad de agentes comprime revisiÃ³n |
| OKR trimestral | Ciclo (4-6 semanas) | EjecuciÃ³n rÃ¡pida permite iterar mÃ¡s |
| Planning Poker | ELIMINADO | Agentes no tienen sesgo de estimaciÃ³n |
| Velocidad (pts/sprint) | CpH + Tasa AceptaciÃ³n + Cycle Time | MÃ©tricas econÃ³micas reales |
| Pair Programming | Cross-eval entre agentes | No necesitan socializar conocimiento |
| Retrospectiva | Retrospectiva AnalÃ­tica | Datos operacionales, no emociÃ³n |
| Scrum Master | Operador | De facilitador social a ingeniero de enjambre |
| Equipo desarrollador | Enjambre auto-evolutivo + Sentinel | Agentes especializados + meta-agente auditor |
| Board estÃ¡tico | Tablero Neural + tarjetas pÃºrpura | Dashboard tiempo real + auto-propuestas |
| TDD | TDD + Evals (incl. seguridad + adversarial) | Evals como TDD organizacional anti-alucinaciÃ³n |
| Trabajo no planificado | Preservado (amarillo + BAU OKR) | Kelly tiene razÃ³n: lo no planificado es valioso |
| Productos no proyectos | Reforzado: software longevo | Agentes mantienen software indefinidamente* |
| Gobernanza de proyecto | Gobernanza multi-nivel HCAI | 4 loops: humano, org, ecosistema, sociedad |
| Backlog estÃ¡tico | Backlog predictivo + flujo | Agentes proponen historias + PO cura |
| Deploy con staging | Ship fast, eval faster, rollback | Evals + feature flags reemplazan staging |
| (sin equivalente) | Roles satÃ©lite | Domain experts, compliance, security, UX |
| (sin equivalente) | Modos de fallo + circuit breakers | Resiliencia diseÃ±ada, no improvisada |
| (sin equivalente) | Modelo de transiciÃ³n | MigraciÃ³n gradual, no big bang |

*\*Longevo, no inmortal. Ver Â§11.2 para matices sobre obsolescencia ecosistÃ©mica y regulatoria.*

## 17.3 Los 12 Axiomas de Xanpan::Agents v2.1

1. **Humano define QUÃ‰ y POR QUÃ‰. Agente resuelve CÃ“MO.** (Invariante fundamental.)
2. **Cada historia debe entregar valor de negocio.** (Invariante Kelly.)
3. **OKRs gobiernan la direcciÃ³n. El backlog es derivado, no primario.**
4. **La calidad es gratis si inviertes en evals.** (EvoluciÃ³n del axioma Crosby/Kelly.)
5. **El coste de token es el nuevo recurso escaso. GestiÃ³nalo como presupuesto.**
6. **Human-in-the-loop para valor y riesgo. AutonomÃ­a para todo lo demÃ¡s.**
7. **El software es un activo vivo y longevo.** (Invariante Kelly/Continuous Digital, amplificado.)
8. **Visualiza todo. El tablero neural es el sistema nervioso.**
9. **Mide, no persigas.** (Principio Kelly contra Goodhart.)
10. **Alta automatizaciÃ³n Y alto control humano. No hay trade-off.** (Principio HCAI de Shneiderman.)
11. **El enjambre se auto-evoluciona bajo gobernanza humana.** (Con Sentinel auditado y circuit breakers.)
12. **DiseÃ±a para la curva exponencialâ€”pero incluye modo degradado.** (HipÃ³tesis de trabajo, no axioma.)

---

*Xanpan::Agents v2.1 no es especulaciÃ³n futurista. Es una reconstrucciÃ³n desde primeros principios de lo que el desarrollo Ã¡gil debe ser cuando los ejecutores cambian de especie cognitiva, fundamentada en los marcos de HCAI que aseguran que la velocidad exponencial sirva a valores humanos. Kelly construyÃ³ sobre la premisa de equipos humanos con limitaciones humanas. Al remover esas limitaciones y sustituirlas por limitaciones de LLM (alucinaciÃ³n, coste, ventana de contexto), la metodologÃ­a se transforma pero los invariantes de valor, calidad, mejora continua y centralidad humana permanecen intactos. Eso es lo que hace a Kelly, y a HCAI, atemporales.*

---

# 18. ApÃ©ndice: Korvoâ€“Korax como Proof of Concept

## 18.1 El sistema personal como laboratorio

Antes de que Xanpan::Agents fuera un documento, fue una prÃ¡ctica. El sistema Korvoâ€“Korax es un prototipo de esta metodologÃ­a a escala personalâ€”un equipo de un humano con un enjambre de uno. No es una implementaciÃ³n perfecta; es un laboratorio donde las ideas se testean con fricciÃ³n real.

## 18.2 Mapeo de conceptos

| Concepto Xanpan::Agents | ImplementaciÃ³n Korvoâ€“Korax |
|---|---|
| Product Owner | Korvo (definiciÃ³n de valor y direcciÃ³n) |
| Operador | Korvo (dual-hat: configura y opera el sistema) |
| Enjambre | Korax + sub-agentes segÃºn tarea |
| OKRs | GTD + sistema de proyectos con revisiones semanales |
| Evals | Invariantes PCA (Protocol de Coherencia Atencional) |
| Sentinel | Heartbeats + mecanismo de detecciÃ³n de colapso |
| Tarjetas pÃºrpura | Propuestas proactivas generadas en heartbeats |
| Context engineering | AGENTS.md + SOUL.md + MEMORY.md |
| Model Router | Fallback chain: sonnet â†’ gpt-5.2 â†’ kimi â†’ glm5 |
| Tablero Neural | Estado del workspace + mÃ©tricas de sesiÃ³n |

## 18.3 La violaciÃ³n consciente: dual-hat PO/Operador

La implementaciÃ³n personal viola deliberadamente la separaciÃ³n de concerns que el Â§2 propone: Korvo es simultÃ¡neamente PO y Operador. Esta violaciÃ³n tiene consecuencias predecibles:

- **Sesgo de confirmaciÃ³n amplificado:** Quien define el valor es quien configura al ejecutor. No hay segundo par de ojos humano que cuestione ni la priorizaciÃ³n ni la configuraciÃ³n.
- **Fatiga atencional compuesta:** Mantener context engineering + evaluar entregas + definir valor consume el mismo recurso escaso (atenciÃ³n humana) sin posibilidad de delegaciÃ³n.
- **El PCA como compensador:** El Protocol de Coherencia Atencional es el mecanismo que compensa esta falta de separaciÃ³n: un framework de gobernanza personal que detecta drift, mantiene coherencia, y dispara alertas cuando la atenciÃ³n se fragmenta.

## 18.4 Lecciones observadas

Lecciones del laboratorio Korvoâ€“Korax que informaron el diseÃ±o de Xanpan::Agents:

1. **El context engineering es MÃS difÃ­cil de lo que parece.** Mantener AGENTS.md actualizado es trabajo cognitivo significativo. â†’ LlevÃ³ a la propuesta de Sentinel como mantenedor de context (Â§2.2).
2. **Los heartbeats como proto-Sentinel funcionan.** La detecciÃ³n proactiva de problemas con propuestas de acciÃ³n subordinadas a aprobaciÃ³n humana es el patrÃ³n mÃ¡s robusto encontrado. â†’ LlevÃ³ al diseÃ±o del Sentinel y las tarjetas pÃºrpura.
3. **La diversidad de modelos importa.** Usar un solo provider crea blind spots. El fallback chain no es solo redundancia; es diversidad cognitiva. â†’ LlevÃ³ al principio de diversidad de modelos en Â§15.1.
4. **El backlog predictivo emerge naturalmente.** Cuando el agente tiene suficiente contexto, empieza a sugerir tareas antes de que el humano las piense. â†’ LlevÃ³ al concepto de backlog predictivo.
5. **La curva exponencial se siente.** Lo que era imposible hace 6 meses ahora es rutina. Pero la sensaciÃ³n no es lineal: hay mesetas seguidas de saltos. â†’ LlevÃ³ a tratar la exponencialidad como hipÃ³tesis con modo degradado (Â§14, Â§15.5).

## 18.5 Limitaciones como proof of concept

Korvoâ€“Korax es un N=1. Las limitaciones como proof of concept son severas:

- **No escala a equipos.** Un sistema personal no demuestra que la metodologÃ­a funcione con mÃºltiples humanos.
- **No tiene separaciÃ³n de roles real.** El dual-hat hace imposible validar que PO/Operador/Sentinel funcionen como roles independientes.
- **No tiene mÃ©tricas formales.** No hay CpH, TA, ni Cycle Time instrumentados. Las observaciones son cualitativas.
- **Survivor bias.** Reportamos lo que funciona; los fracasos se olvidan o se racionalizan.

La funciÃ³n de este apÃ©ndice no es probar que Xanpan::Agents funciona. Es documentar que las ideas centrales â€”context engineering, meta-agente supervisor, backlog predictivo, gobernanza humana de enjambreâ€” **emergieron de la prÃ¡ctica real antes de ser formalizadas**. La teorÃ­a siguiÃ³ a la experiencia, no al revÃ©s. Kelly aprobarÃ­a.

---

*Fin del documento. Xanpan::Agents v2.1. Febrero 2026.*
