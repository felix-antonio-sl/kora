_manifest:
  urn: "urn:kora:doc:nodes-plugins-providers-web:1.0.0"
  federation:
    visibility: internal
    license: "Proprietary"
  compatibility:
    min_consumer_version: "1.0.0"
    breaking_changes_from: null
  resolution:
    canonical_url: "file://knowledge/domains/moltbot/docs/operations/kb_operations_nodes_plugins_providers_web.yaml"
    mirrors: []
  provenance:
    created_by: "Moltbot Docs"
    created_at: "2026-01-29"
    last_modified_by: "Codex"
    last_modified_at: "2026-01-29"
    signature: null

ID: MOLTBOT-KB-OPERATIONS-NODES-PLUGINS-PROVIDERS-WEB-01
Version: 1.0.0
Status: Draft
Human-Creator: Moltbot Docs
Human-Editor: Codex
Model-Collaborator: OpenAI-Codex
Creation-Date: '2026-01-29'
Modification-Date: '2026-01-29'
Ctx: 'Moltbot operations: nodes, plugins, providers, web'
LLM_Parsing_Instructions:
  ID: KODA-LLM-PARSER-01
  Req: Mandatory block following Metadata.
  Prohib: Using for artifact creation or translation.
  Content: |-
    BEGIN_LLM_INSTRUCTIONS
    You are an AI agent consuming a KODA artifact. Parse with absolute fidelity.

    FIDELITY: Preserve meat (essential information) and skeleton (structure: headers, IDs, lists, tables) with zero loss. Ignore fat (filler words, rhetoric, stylistic prose).

    LEXICON (expand before processing): Act->Action, Cond->Condition, Ctx->Context, Ctx_Required->Required External Reference, Ctx_Optional->Optional External Reference, Def->Definition, Ex->Example, Mssn->Mission, Obj->Objective, Proc->Process, Purp->Purpose, Ref->Reference, XRef->Cross-Artifact Reference, XRef_Required->Mandatory Cross-Artifact Reference, Req->Requirement, Res->Result, Src->Source, Prohib->Prohibition, Warn->Warning, Just->Justification, Rec->Recommendation

    REFERENCE POLICY: Ref: is internal only—must point to existing ID within THIS document. XRef/XRef_Required: are external only—must point to a URN (optionally with #ID fragment) in another artifact. External documents without specific ID use Ctx:, Ctx_Required:, or Ctx_Optional:.

    LANGUAGE POLICY: Keywords in English, content in original language. Never translate content.
    END_LLM_INSTRUCTIONS
Purp: 'Operations: nodes/plugins/providers/web'
Src:
- File: output/nodes.md
- File: output/nodes/audio.md
- File: output/nodes/camera.md
- File: output/nodes/images.md
- File: output/nodes/location-command.md
- File: output/nodes/talk.md
- File: output/nodes/voicewake.md
- File: output/plugin.md
- File: output/plugins/voice-call.md
- File: output/plugins/zalouser.md
- File: output/providers.md
- File: output/bedrock.md
- File: output/providers/anthropic.md
- File: output/providers/glm.md
- File: output/providers/minimax.md
- File: output/providers/models.md
- File: output/providers/moonshot.md
- File: output/providers/openai.md
- File: output/providers/opencode.md
- File: output/providers/openrouter.md
- File: output/providers/synthetic.md
- File: output/providers/vercel-ai-gateway.md
- File: output/providers/zai.md
- File: output/web.md
- File: output/web/control-ui.md
- File: output/web/dashboard.md
- File: output/web/webchat.md
Sections:
- ID: NODES-AUDIO
  Src:
    File: output/nodes/audio.md
    URL: https://docs.molt.bot/nodes/audio
  Facts: |-
    H1: Audio - Moltbot
    Nodes & Media
    H1: Audio
    Audio / Voice Notes - 2026-01-17
    What works
    - **Media understanding (audio)** : If audio understanding is enabled (or autodetected), Moltbot:
    - Locates the first audio attachment (local path or URL) and downloads it if needed.
    - Enforces `maxBytes` before sending to each model entry.
    - Runs the first eligible model entry in order (provider or CLI).
    - If it fails or skips (size/timeout), it tries the next entry.
    - On success, it replaces `Body` with an `[Audio]` block and sets `{{Transcript}}`.
    - **Command parsing** : When transcription succeeds, `CommandBody`/`RawBody` are set to the transcript so slash commands still work.
    - **Verbose logging** : In `--verbose`, we log when transcription runs and when it replaces the body.
    Auto-detection (default)
    If you **don't configure models** and `tools.media.audio.enabled` is **not** set to `false`, Moltbot auto-detects in this order and stops at the first working option:
    - **Local CLIs** (if installed)
    - `sherpa-onnx-offline` (requires `SHERPA_ONNX_MODEL_DIR` with encoder/decoder/joiner/tokens)
    - `whisper-cli` (from `whisper-cpp`; uses `WHISPER_CPP_MODEL` or the bundled tiny model)
    - `whisper` (Python CLI; downloads models automatically)
    - **Gemini CLI** (`gemini`) using `read_many_files`
    - **Provider keys** (OpenAI -> Groq -> Deepgram -> Google)
    To disable auto-detection, set `tools.media.audio.enabled: false`. To customize, set `tools.media.audio.models`. Note: Binary detection is best-effort across macOS/Linux/Windows; ensure the CLI is on `PATH` (we expand `~`), or set an explicit CLI model with a full command path.
    Config examples
    Provider + CLI fallback (OpenAI + Whisper CLI)
    Provider-only with scope gating
    Provider-only (Deepgram)
    Notes & limits
    - Provider auth follows the standard model auth order (auth profiles, env vars, `models.providers.*.apiKey`).
    - Deepgram picks up `DEEPGRAM_API_KEY` when `provider: "deepgram"` is used.
    - Deepgram setup details: [Deepgram (audio transcription)](/providers/deepgram).
    - Audio providers can override `baseUrl`, `headers`, and `providerOptions` via `tools.media.audio`.
    - Default size cap is 20MB (`tools.media.audio.maxBytes`). Oversize audio is skipped for that model and the next entry is tried.
    - Default `maxChars` for audio is **unset** (full transcript). Set `tools.media.audio.maxChars` or per-entry `maxChars` to trim output.
    - OpenAI auto default is `gpt-4o-mini-transcribe`; set `model: "gpt-4o-transcribe"` for higher accuracy.
    - Use `tools.media.audio.attachments` to process multiple voice notes (`mode: "all"` \+ `maxAttachments`).
    - Transcript is available to templates as `{{Transcript}}`.
    - CLI stdout is capped (5MB); keep CLI output concise.
    Gotchas
    - Scope rules use first-match wins. `chatType` is normalized to `direct`, `group`, or `room`.
    - Ensure your CLI exits 0 and prints plain text; JSON needs to be massaged via `jq -r .text`.
    - Keep timeouts reasonable (`timeoutSeconds`, default 60s) to avoid blocking the reply queue.
  Ex:
  - ID: EX-NODES-AUDIO-3431825079
    Ctx: Copy
    Body: |-
      {
      tools: {
      media: {
      audio: {
      enabled: true,
      maxBytes: 20971520,
      models: [
      { provider: "openai", model: "gpt-4o-mini-transcribe" },
      {
      type: "cli",
      command: "whisper",
      args: ["--model", "base", "{{MediaPath}}"],
      timeoutSeconds: 45
      }
      ]
      }
      }
      }
      }
  - ID: EX-NODES-AUDIO-AB0D42CAF7
    Ctx: Copy
    Body: |-
      {
      tools: {
      media: {
      audio: {
      enabled: true,
      scope: {
      default: "allow",
      rules: [
      { action: "deny", match: { chatType: "group" } }
      ]
      },
      models: [
      { provider: "openai", model: "gpt-4o-mini-transcribe" }
      ]
      }
      }
      }
      }
  - ID: EX-NODES-AUDIO-D8AAAA1523
    Ctx: Copy
    Body: |-
      {
      tools: {
      media: {
      audio: {
      enabled: true,
      models: [{ provider: "deepgram", model: "nova-3" }]
      }
      }
      }
      }
- ID: NODES-CAMERA
  Src:
    File: output/nodes/camera.md
    URL: https://docs.molt.bot/nodes/camera
  Facts: |-
    H1: Camera - Moltbot
    Nodes & Media
    H1: Camera
    Camera capture (agent)
    Moltbot supports **camera capture** for agent workflows:
    - **iOS node** (paired via Gateway): capture a **photo** (`jpg`) or **short video clip** (`mp4`, with optional audio) via `node.invoke`.
    - **Android node** (paired via Gateway): capture a **photo** (`jpg`) or **short video clip** (`mp4`, with optional audio) via `node.invoke`.
    - **macOS app** (node via Gateway): capture a **photo** (`jpg`) or **short video clip** (`mp4`, with optional audio) via `node.invoke`.
    All camera access is gated behind **user-controlled settings**.
    iOS node
    User setting (default on)
    - iOS Settings tab -> **Camera** -> **Allow Camera** (`camera.enabled`)
    - Default: **on** (missing key is treated as enabled).
    - When off: `camera.*` commands return `CAMERA_DISABLED`.
    Commands (via Gateway `node.invoke`)
    - `camera.list`
    - Response payload:
    - `devices`: array of `{ id, name, position, deviceType }`
    - `camera.snap`
    - Params:
    - `facing`: `front|back` (default: `front`)
    - `maxWidth`: number (optional; default `1600` on the iOS node)
    - `quality`: `0..1` (optional; default `0.9`)
    - `format`: currently `jpg`
    - `delayMs`: number (optional; default `0`)
    - `deviceId`: string (optional; from `camera.list`)
    - Response payload:
    - `format: "jpg"`
    - `base64: "<...>"`
    - `width`, `height`
    - Payload guard: photos are recompressed to keep the base64 payload under 5 MB.
    - `camera.clip`
    - Params:
    - `facing`: `front|back` (default: `front`)
    - `durationMs`: number (default `3000`, clamped to a max of `60000`)
    - `includeAudio`: boolean (default `true`)
    - `format`: currently `mp4`
    - `deviceId`: string (optional; from `camera.list`)
    - Response payload:
    - `format: "mp4"`
    - `base64: "<...>"`
    - `durationMs`
    - `hasAudio`
    Foreground requirement
    Like `canvas.*`, the iOS node only allows `camera.*` commands in the **foreground**. Background invocations return `NODE_BACKGROUND_UNAVAILABLE`.
    CLI helper (temp files + MEDIA)
    The easiest way to get attachments is via the CLI helper, which writes decoded media to a temp file and prints `MEDIA:<path>`. Examples:
    Notes:
    - `nodes camera snap` defaults to **both** facings to give the agent both views.
    - Output files are temporary (in the OS temp directory) unless you build your own wrapper.
    Android node
    User setting (default on)
    - Android Settings sheet -> **Camera** -> **Allow Camera** (`camera.enabled`)
    - Default: **on** (missing key is treated as enabled).
    - When off: `camera.*` commands return `CAMERA_DISABLED`.
    Permissions
    - Android requires runtime permissions:
    - `CAMERA` for both `camera.snap` and `camera.clip`.
    - `RECORD_AUDIO` for `camera.clip` when `includeAudio=true`.
    If permissions are missing, the app will prompt when possible; if denied, `camera.*` requests fail with a `*_PERMISSION_REQUIRED` error.
    Foreground requirement
    Like `canvas.*`, the Android node only allows `camera.*` commands in the **foreground**. Background invocations return `NODE_BACKGROUND_UNAVAILABLE`.
    Payload guard
    Photos are recompressed to keep the base64 payload under 5 MB.
    macOS app
    User setting (default off)
    The macOS companion app exposes a checkbox:
    - **Settings -> General -> Allow Camera** (`moltbot.cameraEnabled`)
    - Default: **off**
    - When off: camera requests return "Camera disabled by user".
    CLI helper (node invoke)
    Use the main `moltbot` CLI to invoke camera commands on the macOS node. Examples:
    Notes:
    - `moltbot nodes camera snap` defaults to `maxWidth=1600` unless overridden.
    - On macOS, `camera.snap` waits `delayMs` (default 2000ms) after warm-up/exposure settle before capturing.
    - Photo payloads are recompressed to keep base64 under 5 MB.
    Safety + practical limits
    - Camera and microphone access trigger the usual OS permission prompts (and require usage strings in Info.plist).
    - Video clips are capped (currently `<= 60s`) to avoid oversized node payloads (base64 overhead + message limits).
    macOS screen video (OS-level)
    For _screen_ video (not camera), use the macOS companion:
    Notes:
    - Requires macOS **Screen Recording** permission (TCC).
  Ex:
  - ID: EX-NODES-CAMERA-05358AC3CF
    Ctx: Copy
    Body: |-
      moltbot nodes camera snap --node <id>               # default: both front + back (2 MEDIA lines)
      moltbot nodes camera snap --node <id> --facing front
      moltbot nodes camera clip --node <id> --duration 3000
      moltbot nodes camera clip --node <id> --no-audio
  - ID: EX-NODES-CAMERA-38A9C017B2
    Ctx: Copy
    Body: |-
      moltbot nodes camera list --node <id>            # list camera ids
      moltbot nodes camera snap --node <id>            # prints MEDIA:<path>
      moltbot nodes camera snap --node <id> --max-width 1280
      moltbot nodes camera snap --node <id> --delay-ms 2000
      moltbot nodes camera snap --node <id> --device-id <id>
      moltbot nodes camera clip --node <id> --duration 10s          # prints MEDIA:<path>
      moltbot nodes camera clip --node <id> --duration-ms 3000      # prints MEDIA:<path> (legacy flag)
      moltbot nodes camera clip --node <id> --device-id <id>
      moltbot nodes camera clip --node <id> --no-audio
  - ID: EX-NODES-CAMERA-AE5AFB4FE8
    Ctx: Copy
    Body: 'moltbot nodes screen record --node <id> --duration 10s --fps 15   # prints MEDIA:<path>'
- ID: NODES-IMAGES
  Src:
    File: output/nodes/images.md
    URL: https://docs.molt.bot/nodes/images
  Facts: |-
    H1: Images - Moltbot
    Nodes & Media
    H1: Images
    Image & Media Support - 2025-12-05
    The WhatsApp channel runs via **Baileys Web**. This document captures the current media handling rules for send, gateway, and agent replies.
    Goals
    - Send media with optional captions via `moltbot message send --media`.
    - Allow auto-replies from the web inbox to include media alongside text.
    - Keep per-type limits sane and predictable.
    CLI Surface
    - `moltbot message send --media <path-or-url> [--message <caption>]`
    - `--media` optional; caption can be empty for media-only sends.
    - `--dry-run` prints the resolved payload; `--json` emits `{ channel, to, messageId, mediaUrl, caption }`.
    WhatsApp Web channel behavior
    - Input: local file path **or** HTTP(S) URL.
    - Flow: load into a Buffer, detect media kind, and build the correct payload:
    - **Images:** resize & recompress to JPEG (max side 2048px) targeting `agents.defaults.mediaMaxMb` (default 5 MB), capped at 6 MB.
    - **Audio/Voice/Video:** pass-through up to 16 MB; audio is sent as a voice note (`ptt: true`).
    - **Documents:** anything else, up to 100 MB, with filename preserved when available.
    - WhatsApp GIF-style playback: send an MP4 with `gifPlayback: true` (CLI: `--gif-playback`) so mobile clients loop inline.
    - MIME detection prefers magic bytes, then headers, then file extension.
    - Caption comes from `--message` or `reply.text`; empty caption is allowed.
    - Logging: non-verbose shows ``/``; verbose includes size and source path/URL.
    Auto-Reply Pipeline
    - `getReplyFromConfig` returns `{ text?, mediaUrl?, mediaUrls? }`.
    - When media is present, the web sender resolves local paths or URLs using the same pipeline as `moltbot message send`.
    - Multiple media entries are sent sequentially if provided.
    Inbound Media to Commands (Pi)
    - When inbound web messages include media, Moltbot downloads to a temp file and exposes templating variables:
    - `{{MediaUrl}}` pseudo-URL for the inbound media.
    - `{{MediaPath}}` local temp path written before running the command.
    - When a per-session Docker sandbox is enabled, inbound media is copied into the sandbox workspace and `MediaPath`/`MediaUrl` are rewritten to a relative path like `media/inbound/<filename>`.
    - Media understanding (if configured via `tools.media.*` or shared `tools.media.models`) runs before templating and can insert `[Image]`, `[Audio]`, and `[Video]` blocks into `Body`.
    - Audio sets `{{Transcript}}` and uses the transcript for command parsing so slash commands still work.
    - Video and image descriptions preserve any caption text for command parsing.
    - By default only the first matching image/audio/video attachment is processed; set `tools.media.<cap>.attachments` to process multiple attachments.
    Limits & Errors
    **Outbound send caps (WhatsApp web send)**
    - Images: ~6 MB cap after recompression.
    - Audio/voice/video: 16 MB cap; documents: 100 MB cap.
    - Oversize or unreadable media -> clear error in logs and the reply is skipped.
    **Media understanding caps (transcription/description)**
    - Image default: 10 MB (`tools.media.image.maxBytes`).
    - Audio default: 20 MB (`tools.media.audio.maxBytes`).
    - Video default: 50 MB (`tools.media.video.maxBytes`).
    - Oversize media skips understanding, but replies still go through with the original body.
    Notes for Tests
    - Cover send + reply flows for image/audio/document cases.
    - Validate recompression for images (size bound) and voice-note flag for audio.
    - Ensure multi-media replies fan out as sequential sends.
- ID: NODES-LOCATION-COMMAND
  Src:
    File: output/nodes/location-command.md
    URL: https://docs.molt.bot/nodes/location-command
  Facts: |-
    H1: Location command - Moltbot
    Nodes & Media
    H1: Location command
    Location command (nodes)
    TL;DR
    - `location.get` is a node command (via `node.invoke`).
    - Off by default.
    - Settings use a selector: Off / While Using / Always.
    - Separate toggle: Precise Location.
    Why a selector (not just a switch)
    OS permissions are multi-level. We can expose a selector in-app, but the OS still decides the actual grant.
    - iOS/macOS: user can choose **While Using** or **Always** in system prompts/Settings. App can request upgrade, but OS may require Settings.
    - Android: background location is a separate permission; on Android 10+ it often requires a Settings flow.
    - Precise location is a separate grant (iOS 14+ "Precise", Android "fine" vs "coarse").
    Selector in UI drives our requested mode; actual grant lives in OS settings.
    Settings model
    Per node device:
    - `location.enabledMode`: `off | whileUsing | always`
    - `location.preciseEnabled`: bool
    UI behavior:
    - Selecting `whileUsing` requests foreground permission.
    - Selecting `always` first ensures `whileUsing`, then requests background (or sends user to Settings if required).
    - If OS denies requested level, revert to the highest granted level and show status.
    Permissions mapping (node.permissions)
    Optional. macOS node reports `location` via the permissions map; iOS/Android may omit it.
    Command: `location.get`
    Called via `node.invoke`. Params (suggested):
    Response payload:
    Errors (stable codes):
    - `LOCATION_DISABLED`: selector is off.
    - `LOCATION_PERMISSION_REQUIRED`: permission missing for requested mode.
    - `LOCATION_BACKGROUND_UNAVAILABLE`: app is backgrounded but only While Using allowed.
    - `LOCATION_TIMEOUT`: no fix in time.
    - `LOCATION_UNAVAILABLE`: system failure / no providers.
    Background behavior (future)
    Goal: model can request location even when node is backgrounded, but only when:
    - User selected **Always**.
    - OS grants background location.
    - App is allowed to run in background for location (iOS background mode / Android foreground service or special allowance).
    Push-triggered flow (future):
    - Gateway sends a push to the node (silent push or FCM data).
    - Node wakes briefly and requests location from the device.
    - Node forwards payload to Gateway.
    Notes:
    - iOS: Always permission + background location mode required. Silent push may be throttled; expect intermittent failures.
    - Android: background location may require a foreground service; otherwise, expect denial.
    Model/tooling integration
    - Tool surface: `nodes` tool adds `location_get` action (node required).
    - CLI: `moltbot nodes location get --node <id>`.
    - Agent guidelines: only call when user enabled location and understands the scope.
    UX copy (suggested)
    - Off: "Location sharing is disabled."
    - While Using: "Only when Moltbot is open."
    - Always: "Allow background location. Requires system permission."
    - Precise: "Use precise GPS location. Toggle off to share approximate location."
  Ex:
  - ID: EX-NODES-LOCATION-COMMAND-2E4E039B29
    Ctx: Copy
    Body: |-
      {
      "timeoutMs": 10000,
      "maxAgeMs": 15000,
      "desiredAccuracy": "coarse|balanced|precise"
      }
  - ID: EX-NODES-LOCATION-COMMAND-674701978A
    Ctx: Copy
    Body: |-
      {
      "lat": 48.20849,
      "lon": 16.37208,
      "accuracyMeters": 12.5,
      "altitudeMeters": 182.0,
      "speedMps": 0.0,
      "headingDeg": 270.0,
      "timestamp": "2026-01-03T12:34:56.000Z",
      "isPrecise": true,
      "source": "gps|wifi|cell|unknown"
      }
- ID: NODES-TALK
  Src:
    File: output/nodes/talk.md
    URL: https://docs.molt.bot/nodes/talk
  Facts: |-
    H1: Talk - Moltbot
    Nodes & Media
    H1: Talk
    Talk Mode
    Talk mode is a continuous voice conversation loop:
    - Listen for speech
    - Send transcript to the model (main session, chat.send)
    - Wait for the response
    - Speak it via ElevenLabs (streaming playback)
    Behavior (macOS)
    - **Always-on overlay** while Talk mode is enabled.
    - **Listening -> Thinking -> Speaking** phase transitions.
    - On a **short pause** (silence window), the current transcript is sent.
    - Replies are **written to WebChat** (same as typing).
    - **Interrupt on speech** (default on): if the user starts talking while the assistant is speaking, we stop playback and note the interruption timestamp for the next prompt.
    Voice directives in replies
    The assistant may prefix its reply with a **single JSON line** to control voice:
    Rules:
    - First non-empty line only.
    - Unknown keys are ignored.
    - `once: true` applies to the current reply only.
    - Without `once`, the voice becomes the new default for Talk mode.
    - The JSON line is stripped before TTS playback.
    Supported keys:
    - `voice` / `voice_id` / `voiceId`
    - `model` / `model_id` / `modelId`
    - `speed`, `rate` (WPM), `stability`, `similarity`, `style`, `speakerBoost`
    - `seed`, `normalize`, `lang`, `output_format`, `latency_tier`
    - `once`
    Config (`~/.clawdbot/moltbot.json`)
    Defaults:
    - `interruptOnSpeech`: true
    - `voiceId`: falls back to `ELEVENLABS_VOICE_ID` / `SAG_VOICE_ID` (or first ElevenLabs voice when API key is available)
    - `modelId`: defaults to `eleven_v3` when unset
    - `apiKey`: falls back to `ELEVENLABS_API_KEY` (or gateway shell profile if available)
    - `outputFormat`: defaults to `pcm_44100` on macOS/iOS and `pcm_24000` on Android (set `mp3_*` to force MP3 streaming)
    macOS UI
    - Menu bar toggle: **Talk**
    - Config tab: **Talk Mode** group (voice id + interrupt toggle)
    - Overlay:
    - **Listening** : cloud pulses with mic level
    - **Thinking** : sinking animation
    - **Speaking** : radiating rings
    - Click cloud: stop speaking
    - Click X: exit Talk mode
    Notes
    - Requires Speech + Microphone permissions.
    - Uses `chat.send` against session key `main`.
    - TTS uses ElevenLabs streaming API with `ELEVENLABS_API_KEY` and incremental playback on macOS/iOS/Android for lower latency.
    - `stability` for `eleven_v3` is validated to `0.0`, `0.5`, or `1.0`; other models accept `0..1`.
    - `latency_tier` is validated to `0..4` when set.
    - Android supports `pcm_16000`, `pcm_22050`, `pcm_24000`, and `pcm_44100` output formats for low-latency AudioTrack streaming.
  Ex:
  - ID: EX-NODES-TALK-21D9B593A0
    Ctx: Copy
    Body: '{"voice":"<voice-id>","once":true}'
  - ID: EX-NODES-TALK-90F4C2A75D
    Ctx: Copy
    Body: |-
      {
      "talk": {
      "voiceId": "elevenlabs_voice_id",
      "modelId": "eleven_v3",
      "outputFormat": "mp3_44100_128",
      "apiKey": "elevenlabs_api_key",
      "interruptOnSpeech": true
      }
      }
- ID: NODES-VOICEWAKE
  Src:
    File: output/nodes/voicewake.md
    URL: https://docs.molt.bot/nodes/voicewake
  Facts: |-
    H1: Voicewake - Moltbot
    Nodes & Media
    H1: Voicewake
    Voice Wake (Global Wake Words)
    Moltbot treats **wake words as a single global list** owned by the **Gateway**.
    - There are **no per-node custom wake words**.
    - **Any node/app UI may edit** the list; changes are persisted by the Gateway and broadcast to everyone.
    - Each device still keeps its own **Voice Wake enabled/disabled** toggle (local UX + permissions differ).
    Storage (Gateway host)
    Wake words are stored on the gateway machine at:
    - `~/.clawdbot/settings/voicewake.json`
    Shape:
    Protocol
    Methods
    - `voicewake.get` -> `{ triggers: string[] }`
    - `voicewake.set` with params `{ triggers: string[] }` -> `{ triggers: string[] }`
    Notes:
    - Triggers are normalized (trimmed, empties dropped). Empty lists fall back to defaults.
    - Limits are enforced for safety (count/length caps).
    Events
    - `voicewake.changed` payload `{ triggers: string[] }`
    Who receives it:
    - All WebSocket clients (macOS app, WebChat, etc.)
    - All connected nodes (iOS/Android), and also on node connect as an initial "current state" push.
    Client behavior
    macOS app
    - Uses the global list to gate `VoiceWakeRuntime` triggers.
    - Editing "Trigger words" in Voice Wake settings calls `voicewake.set` and then relies on the broadcast to keep other clients in sync.
    iOS node
    - Uses the global list for `VoiceWakeManager` trigger detection.
    - Editing Wake Words in Settings calls `voicewake.set` (over the Gateway WS) and also keeps local wake-word detection responsive.
    Android node
    - Exposes a Wake Words editor in Settings.
    - Calls `voicewake.set` over the Gateway WS so edits sync everywhere.
  Ex:
  - ID: EX-NODES-VOICEWAKE-F931ABA3E4
    Ctx: Copy
    Body: '{ "triggers": ["clawd", "claude", "computer"], "updatedAtMs": 1730000000000 }'
- ID: PLUGINS-VOICE-CALL
  Src:
    File: output/plugins/voice-call.md
    URL: https://docs.molt.bot/plugins/voice-call
  Facts: |-
    H1: Voice call - Moltbot
    Tools & Skills
    H1: Voice call
    Voice Call (plugin)
    Voice calls for Moltbot via a plugin. Supports outbound notifications and multi-turn conversations with inbound policies. Current providers:
    - `twilio` (Programmable Voice + Media Streams)
    - `telnyx` (Call Control v2)
    - `plivo` (Voice API + XML transfer + GetInput speech)
    - `mock` (dev/no network)
    Quick mental model:
    - Install plugin
    - Restart Gateway
    - Configure under `plugins.entries.voice-call.config`
    - Use `moltbot voicecall ...` or the `voice_call` tool
    Where it runs (local vs remote)
    The Voice Call plugin runs **inside the Gateway process**. If you use a remote Gateway, install/configure the plugin on the **machine running the Gateway** , then restart the Gateway to load it.
    Install
    Option A: install from npm (recommended)
    Restart the Gateway afterwards.
    Option B: install from a local folder (dev, no copying)
    Restart the Gateway afterwards.
    Config
    Set config under `plugins.entries.voice-call.config`:
    Notes:
    - Twilio/Telnyx require a **publicly reachable** webhook URL.
    - Plivo requires a **publicly reachable** webhook URL.
    - `mock` is a local dev provider (no network calls).
    - `skipSignatureVerification` is for local testing only.
    - If you use ngrok free tier, set `publicUrl` to the exact ngrok URL; signature verification is always enforced.
    - `tunnel.allowNgrokFreeTierLoopbackBypass: true` allows Twilio webhooks with invalid signatures **only** when `tunnel.provider="ngrok"` and `serve.bind` is loopback (ngrok local agent). Use for local dev only.
    - Ngrok free tier URLs can change or add interstitial behavior; if `publicUrl` drifts, Twilio signatures will fail. For production, prefer a stable domain or Tailscale funnel.
    TTS for calls
    Voice Call uses the core `messages.tts` configuration (OpenAI or ElevenLabs) for streaming speech on calls. You can override it under the plugin config with the **same shape** - it deepmerges with `messages.tts`.
    Notes:
    - **Edge TTS is ignored for voice calls** (telephony audio needs PCM; Edge output is unreliable).
    - Core TTS is used when Twilio media streaming is enabled; otherwise calls fall back to provider native voices.
    More examples
    Use core TTS only (no override):
    Override to ElevenLabs just for calls (keep core default elsewhere):
    Override only the OpenAI model for calls (deepmerge example):
    Inbound calls
    Inbound policy defaults to `disabled`. To enable inbound calls, set:
    Auto-responses use the agent system. Tune with:
    - `responseModel`
    - `responseSystemPrompt`
    - `responseTimeoutMs`
    CLI
    Agent tool
    Tool name: `voice_call` Actions:
    - `initiate_call` (message, to?, mode?)
    - `continue_call` (callId, message)
    - `speak_to_user` (callId, message)
    - `end_call` (callId)
    - `get_status` (callId)
    This repo ships a matching skill doc at `skills/voice-call/SKILL.md`.
    Gateway RPC
    - `voicecall.initiate` (`to?`, `message`, `mode?`)
    - `voicecall.continue` (`callId`, `message`)
    - `voicecall.speak` (`callId`, `message`)
    - `voicecall.end` (`callId`)
    - `voicecall.status` (`callId`)
  Ex:
  - ID: EX-PLUGINS-VOICE-CALL-F4A5C6F9CE
    Ctx: Copy
    Body: moltbot plugins install @moltbot/voice-call
  - ID: EX-PLUGINS-VOICE-CALL-AAA94CACFA
    Ctx: Copy
    Body: |-
      moltbot plugins install ./extensions/voice-call
      cd ./extensions/voice-call && pnpm install
  - ID: EX-PLUGINS-VOICE-CALL-47236A5BDD
    Ctx: Copy
    Body: |-
      {
      plugins: {
      entries: {
      "voice-call": {
      enabled: true,
      config: {
      provider: "twilio", // or "telnyx" | "plivo" | "mock"
      fromNumber: "+15550001234",
      toNumber: "+15550005678",
  - ID: EX-PLUGINS-VOICE-CALL-8DC62BF4C8
    Body: |-
      twilio: {
      accountSid: "ACxxxxxxxx",
      authToken: "..."
      },
  - ID: EX-PLUGINS-VOICE-CALL-3DFACEA9E8
    Body: |-
      plivo: {
      authId: "MAxxxxxxxxxxxxxxxxxxxx",
      authToken: "..."
      },
  - ID: EX-PLUGINS-VOICE-CALL-90B364B269
    Body: |-
      // Webhook server
      serve: {
      port: 3334,
      path: "/voice/webhook"
      },
  - ID: EX-PLUGINS-VOICE-CALL-82667A430B
    Body: |-
      // Public exposure (pick one)
      // publicUrl: "https://example.ngrok.app/voice/webhook",
      // tunnel: { provider: "ngrok" },
      // tailscale: { mode: "funnel", path: "/voice/webhook" }
  - ID: EX-PLUGINS-VOICE-CALL-2C2FF3EB8F
    Body: |-
      outbound: {
      defaultMode: "notify" // notify | conversation
      },
  - ID: EX-PLUGINS-VOICE-CALL-6FDD0AE032
    Body: |-
      streaming: {
      enabled: true,
      streamPath: "/voice/stream"
      }
      }
      }
      }
      }
      }
  - ID: EX-PLUGINS-VOICE-CALL-9569BBCBD0
    Ctx: Copy
    Body: |-
      {
      tts: {
      provider: "elevenlabs",
      elevenlabs: {
      voiceId: "pMsXgVXv3BLzUgSXRplE",
      modelId: "eleven_multilingual_v2"
      }
      }
      }
  - ID: EX-PLUGINS-VOICE-CALL-F1A1E7C627
    Ctx: Copy
    Body: |-
      {
      messages: {
      tts: {
      provider: "openai",
      openai: { voice: "alloy" }
      }
      }
      }
  - ID: EX-PLUGINS-VOICE-CALL-74A95426F4
    Ctx: Copy
    Body: |-
      {
      plugins: {
      entries: {
      "voice-call": {
      config: {
      tts: {
      provider: "elevenlabs",
      elevenlabs: {
      apiKey: "elevenlabs_key",
      voiceId: "pMsXgVXv3BLzUgSXRplE",
      modelId: "eleven_multilingual_v2"
      }
      }
      }
      }
      }
      }
      }
  - ID: EX-PLUGINS-VOICE-CALL-FB92B9CB41
    Ctx: Copy
    Body: |-
      {
      plugins: {
      entries: {
      "voice-call": {
      config: {
      tts: {
      openai: {
      model: "gpt-4o-mini-tts",
      voice: "marin"
      }
      }
      }
      }
      }
      }
      }
  - ID: EX-PLUGINS-VOICE-CALL-2EB64287F4
    Ctx: Copy
    Body: |-
      {
      inboundPolicy: "allowlist",
      allowFrom: ["+15550001234"],
      inboundGreeting: "Hello! How can I help?"
      }
  - ID: EX-PLUGINS-VOICE-CALL-CBA259E074
    Ctx: Copy
    Body: |-
      moltbot voicecall call --to "+15555550123" --message "Hello from Moltbot"
      moltbot voicecall continue --call-id <id> --message "Any questions?"
      moltbot voicecall speak --call-id <id> --message "One moment"
      moltbot voicecall end --call-id <id>
      moltbot voicecall status --call-id <id>
      moltbot voicecall tail
      moltbot voicecall expose --mode funnel
- ID: PLUGINS-ZALOUSER
  Src:
    File: output/plugins/zalouser.md
    URL: https://docs.molt.bot/plugins/zalouser
  Facts: |-
    H1: Zalouser - Moltbot
    Tools & Skills
    H1: Zalouser
    Zalo Personal (plugin)
    Zalo Personal support for Moltbot via a plugin, using `zca-cli` to automate a normal Zalo user account.
    > **Warning:** Unofficial automation may lead to account suspension/ban. Use at your own risk.
    Naming
    Channel id is `zalouser` to make it explicit this automates a **personal Zalo user account** (unofficial). We keep `zalo` reserved for a potential future official Zalo API integration.
    Where it runs
    This plugin runs **inside the Gateway process**. If you use a remote Gateway, install/configure it on the **machine running the Gateway** , then restart the Gateway.
    Install
    Option A: install from npm
    Restart the Gateway afterwards.
    Option B: install from a local folder (dev)
    Restart the Gateway afterwards.
    Prerequisite: zca-cli
    The Gateway machine must have `zca` on `PATH`:
    Config
    Channel config lives under `channels.zalouser` (not `plugins.entries.*`):
    CLI
    Agent tool
    Tool name: `zalouser` Actions: `send`, `image`, `link`, `friends`, `groups`, `me`, `status`
  Ex:
  - ID: EX-PLUGINS-ZALOUSER-8CF6DA724A
    Ctx: Copy
    Body: moltbot plugins install @moltbot/zalouser
  - ID: EX-PLUGINS-ZALOUSER-BB64E28F83
    Ctx: Copy
    Body: |-
      moltbot plugins install ./extensions/zalouser
      cd ./extensions/zalouser && pnpm install
  - ID: EX-PLUGINS-ZALOUSER-61751E1604
    Ctx: Copy
    Body: zca --version
  - ID: EX-PLUGINS-ZALOUSER-F6101496CA
    Ctx: Copy
    Body: |-
      {
      channels: {
      zalouser: {
      enabled: true,
      dmPolicy: "pairing"
      }
      }
      }
  - ID: EX-PLUGINS-ZALOUSER-0F7E4594C1
    Ctx: Copy
    Body: |-
      moltbot channels login --channel zalouser
      moltbot channels logout --channel zalouser
      moltbot channels status --probe
      moltbot message send --channel zalouser --target <threadId> --message "Hello from Moltbot"
      moltbot directory peers list --channel zalouser --query "name"
- ID: PROVIDERS-ANTHROPIC
  Src:
    File: output/providers/anthropic.md
    URL: https://docs.molt.bot/providers/anthropic
  Facts: |-
    H1: Anthropic - Moltbot
    Providers
    H1: Anthropic
    Anthropic (Claude)
    Anthropic builds the **Claude** model family and provides access via an API. In Moltbot you can authenticate with an API key or a **setup-token**.
    Option A: Anthropic API key
    **Best for:** standard API access and usage-based billing. Create your API key in the Anthropic Console.
    CLI setup
    Config snippet
    Prompt caching (Anthropic API)
    Moltbot does **not** override Anthropic's default cache TTL unless you set it. This is **API-only** ; subscription auth does not honor TTL settings. To set the TTL per model, use `cacheControlTtl` in the model `params`:
    Moltbot includes the `extended-cache-ttl-2025-04-11` beta flag for Anthropic API requests; keep it if you override provider headers (see [/gateway/configuration](/gateway/configuration)).
    Option B: Claude setup-token
    **Best for:** using your Claude subscription.
    Where to get a setup-token
    Setup-tokens are created by the **Claude Code CLI** , not the Anthropic Console. You can run this on **any machine** :
    Paste the token into Moltbot (wizard: **Anthropic token (paste setup-token)**), or run it on the gateway host:
    If you generated the token on a different machine, paste it:
    CLI setup
    Config snippet
    Notes
    - Generate the setup-token with `claude setup-token` and paste it, or run `moltbot models auth setup-token` on the gateway host.
    - If you see "OAuth token refresh failed ..." on a Claude subscription, re-auth with a setup-token. See [/gateway/troubleshooting#oauth-token-refresh-failed-anthropic-claude-subscription](/gateway/troubleshooting#oauth-token-refresh-failed-anthropic-claude-subscription).
    - Auth details + reuse rules are in [/concepts/oauth](/concepts/oauth).
    Troubleshooting
    **401 errors / token suddenly invalid**
    - Claude subscription auth can expire or be revoked. Re-run `claude setup-token` and paste it into the **gateway host**.
    - If the Claude CLI login lives on a different machine, use `moltbot models auth paste-token --provider anthropic` on the gateway host.
    **No API key found for provider "anthropic"**
    - Auth is **per agent**. New agents don't inherit the main agent's keys.
    - Re-run onboarding for that agent, or paste a setup-token / API key on the gateway host, then verify with `moltbot models status`.
    **No credentials found for profile`anthropic:default`**
    - Run `moltbot models status` to see which auth profile is active.
    - Re-run onboarding, or paste a setup-token / API key for that profile.
    **No available auth profile (all in cooldown/unavailable)**
    - Check `moltbot models status --json` for `auth.unusableProfiles`.
    - Add another Anthropic profile or wait for cooldown.
    More: [/gateway/troubleshooting](/gateway/troubleshooting) and [/help/faq](/help/faq).
  Ex:
  - ID: EX-PROVIDERS-ANTHROPIC-122801F538
    Ctx: Copy
    Body: |-
      moltbot onboard
      # choose: Anthropic API key
  - ID: EX-PROVIDERS-ANTHROPIC-AA39525BBA
    Body: |-
      # or non-interactive
      moltbot onboard --anthropic-api-key "$ANTHROPIC_API_KEY"
  - ID: EX-PROVIDERS-ANTHROPIC-1FC50BC44D
    Ctx: Copy
    Body: |-
      {
      env: { ANTHROPIC_API_KEY: "sk-ant-..." },
      agents: { defaults: { model: { primary: "anthropic/claude-opus-4-5" } } }
      }
  - ID: EX-PROVIDERS-ANTHROPIC-B330258885
    Ctx: Copy
    Body: |-
      {
      agents: {
      defaults: {
      models: {
      "anthropic/claude-opus-4-5": {
      params: { cacheControlTtl: "5m" } // or "1h"
      }
      }
      }
      }
      }
  - ID: EX-PROVIDERS-ANTHROPIC-8916C1F211
    Ctx: Copy
    Body: claude setup-token
  - ID: EX-PROVIDERS-ANTHROPIC-CD88CA6FA5
    Ctx: Copy
    Body: moltbot models auth setup-token --provider anthropic
  - ID: EX-PROVIDERS-ANTHROPIC-F31D8BF1ED
    Ctx: Copy
    Body: moltbot models auth paste-token --provider anthropic
  - ID: EX-PROVIDERS-ANTHROPIC-3EE3950BE0
    Ctx: Copy
    Body: |-
      # Paste a setup-token during onboarding
      moltbot onboard --auth-choice setup-token
  - ID: EX-PROVIDERS-ANTHROPIC-0570B133BD
    Ctx: Copy
    Body: |-
      {
      agents: { defaults: { model: { primary: "anthropic/claude-opus-4-5" } } }
      }
- ID: PROVIDERS-GLM
  Src:
    File: output/providers/glm.md
    URL: https://docs.molt.bot/providers/glm
  Facts: |-
    H1: Glm - Moltbot
    Providers
    H1: Glm
    GLM models
    GLM is a **model family** (not a company) available through the Z.AI platform. In Moltbot, GLM models are accessed via the `zai` provider and model IDs like `zai/glm-4.7`.
    CLI setup
    Config snippet
    Notes
    - GLM versions and availability can change; check Z.AI's docs for the latest.
    - Example model IDs include `glm-4.7` and `glm-4.6`.
    - For provider details, see [/providers/zai](/providers/zai).
  Ex:
  - ID: EX-PROVIDERS-GLM-62F75DE21F
    Ctx: Copy
    Body: moltbot onboard --auth-choice zai-api-key
  - ID: EX-PROVIDERS-GLM-98C4785754
    Ctx: Copy
    Body: |-
      {
      env: { ZAI_API_KEY: "sk-..." },
      agents: { defaults: { model: { primary: "zai/glm-4.7" } } }
      }
- ID: PROVIDERS-MINIMAX
  Src:
    File: output/providers/minimax.md
    URL: https://docs.molt.bot/providers/minimax
  Facts: |-
    H1: Minimax - Moltbot
    Providers
    H1: Minimax
    MiniMax
    MiniMax is an AI company that builds the **M2/M2.1** model family. The current coding-focused release is **MiniMax M2.1** (December 23, 2025), built for real-world complex tasks. Source: [MiniMax M2.1 release note](https://www.minimax.io/news/minimax-m21)
    Model overview (M2.1)
    MiniMax highlights these improvements in M2.1:
    - Stronger **multi-language coding** (Rust, Java, Go, C++, Kotlin, Objective-C, TS/JS).
    - Better **web/app development** and aesthetic output quality (including native mobile).
    - Improved **composite instruction** handling for office-style workflows, building on interleaved thinking and integrated constraint execution.
    - **More concise responses** with lower token usage and faster iteration loops.
    - Stronger **tool/agent framework** compatibility and context management (Claude Code, Droid/Factory AI, Cline, Kilo Code, Roo Code, BlackBox).
    - Higher-quality **dialogue and technical writing** outputs.
    MiniMax M2.1 vs MiniMax M2.1 Lightning
    - **Speed:** Lightning is the "fast" variant in MiniMax's pricing docs.
    - **Cost:** Pricing shows the same input cost, but Lightning has higher output cost.
    - **Coding plan routing:** The Lightning back-end isn't directly available on the MiniMax coding plan. MiniMax auto-routes most requests to Lightning, but falls back to the regular M2.1 back-end during traffic spikes.
    Choose a setup
    MiniMax M2.1 - recommended
    **Best for:** hosted MiniMax with Anthropic-compatible API. Configure via CLI:
    - Run `moltbot configure`
    - Select **Model/auth**
    - Choose **MiniMax M2.1**
    MiniMax M2.1 as fallback (Opus primary)
    **Best for:** keep Opus 4.5 as primary, fail over to MiniMax M2.1.
    Optional: Local via LM Studio (manual)
    **Best for:** local inference with LM Studio. We have seen strong results with MiniMax M2.1 on powerful hardware (e.g. a desktop/server) using LM Studio's local server. Configure manually via `moltbot.json`:
    Configure via `moltbot configure`
    Use the interactive config wizard to set MiniMax without editing JSON:
    - Run `moltbot configure`.
    - Select **Model/auth**.
    - Choose **MiniMax M2.1**.
    - Pick your default model when prompted.
    Configuration options
    - `models.providers.minimax.baseUrl`: prefer `https://api.minimax.io/anthropic` (Anthropic-compatible); `https://api.minimax.io/v1` is optional for OpenAI-compatible payloads.
    - `models.providers.minimax.api`: prefer `anthropic-messages`; `openai-completions` is optional for OpenAI-compatible payloads.
    - `models.providers.minimax.apiKey`: MiniMax API key (`MINIMAX_API_KEY`).
    - `models.providers.minimax.models`: define `id`, `name`, `reasoning`, `contextWindow`, `maxTokens`, `cost`.
    - `agents.defaults.models`: alias models you want in the allowlist.
    - `models.mode`: keep `merge` if you want to add MiniMax alongside built-ins.
    Notes
    - Model refs are `minimax/<model>`.
    - Coding Plan usage API: `https://api.minimaxi.com/v1/api/openplatform/coding_plan/remains` (requires a coding plan key).
    - Update pricing values in `models.json` if you need exact cost tracking.
    - Referral link for MiniMax Coding Plan (10% off): [https://platform.minimax.io/subscribe/coding-plan?code=DbXJTRClnb&source=link](https://platform.minimax.io/subscribe/coding-plan?code=DbXJTRClnb&source=link)
    - See [/concepts/model-providers](/concepts/model-providers) for provider rules.
    - Use `moltbot models list` and `moltbot models set minimax/MiniMax-M2.1` to switch.
    Troubleshooting
    "Unknown model: minimax/MiniMax-M2.1"
    This usually means the **MiniMax provider isn't configured** (no provider entry and no MiniMax auth profile/env key found). A fix for this detection is in **2026.1.12** (unreleased at the time of writing). Fix by:
    - Upgrading to **2026.1.12** (or run from source `main`), then restarting the gateway.
    - Running `moltbot configure` and selecting **MiniMax M2.1** , or
    - Adding the `models.providers.minimax` block manually, or
    - Setting `MINIMAX_API_KEY` (or a MiniMax auth profile) so the provider can be injected.
    Make sure the model id is **casesensitive** :
    - `minimax/MiniMax-M2.1`
    - `minimax/MiniMax-M2.1-lightning`
    Then recheck with:
  Ex:
  - ID: EX-PROVIDERS-MINIMAX-1842972F4D
    Ctx: Copy
    Body: |-
      {
      env: { MINIMAX_API_KEY: "sk-..." },
      agents: { defaults: { model: { primary: "minimax/MiniMax-M2.1" } } },
      models: {
      mode: "merge",
      providers: {
      minimax: {
      baseUrl: "https://api.minimax.io/anthropic",
      apiKey: "${MINIMAX_API_KEY}",
      api: "anthropic-messages",
      models: [
      {
      id: "MiniMax-M2.1",
      name: "MiniMax M2.1",
      reasoning: false,
      input: ["text"],
      cost: { input: 15, output: 60, cacheRead: 2, cacheWrite: 10 },
      contextWindow: 200000,
      maxTokens: 8192
      }
      ]
      }
      }
      }
      }
  - ID: EX-PROVIDERS-MINIMAX-825DD3ADB4
    Ctx: Copy
    Body: |-
      {
      env: { MINIMAX_API_KEY: "sk-..." },
      agents: {
      defaults: {
      models: {
      "anthropic/claude-opus-4-5": { alias: "opus" },
      "minimax/MiniMax-M2.1": { alias: "minimax" }
      },
      model: {
      primary: "anthropic/claude-opus-4-5",
      fallbacks: ["minimax/MiniMax-M2.1"]
      }
      }
      }
      }
  - ID: EX-PROVIDERS-MINIMAX-DAB6C82EBE
    Ctx: Copy
    Body: |-
      {
      agents: {
      defaults: {
      model: { primary: "lmstudio/minimax-m2.1-gs32" },
      models: { "lmstudio/minimax-m2.1-gs32": { alias: "Minimax" } }
      }
      },
      models: {
      mode: "merge",
      providers: {
      lmstudio: {
      baseUrl: "http://127.0.0.1:1234/v1",
      apiKey: "lmstudio",
      api: "openai-responses",
      models: [
      {
      id: "minimax-m2.1-gs32",
      name: "MiniMax M2.1 GS32",
      reasoning: false,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 196608,
      maxTokens: 8192
      }
      ]
      }
      }
      }
      }
  - ID: EX-PROVIDERS-MINIMAX-228DF091B5
    Ctx: Copy
    Body: moltbot models list
- ID: PROVIDERS-MODELS
  Src:
    File: output/providers/models.md
    URL: https://docs.molt.bot/providers/models
  Facts: |-
    H1: Models - Moltbot
    Providers
    H1: Models
    Model Providers
    Moltbot can use many LLM providers. Pick one, authenticate, then set the default model as `provider/model`.
    Highlight: Venius (Venice AI)
    Venius is our recommended Venice AI setup for privacy-first inference with an option to use Opus for the hardest tasks.
    - Default: `venice/llama-3.3-70b`
    - Best overall: `venice/claude-opus-45` (Opus remains the strongest)
    See [Venice AI](/providers/venice).
    Quick start (two steps)
    - Authenticate with the provider (usually via `moltbot onboard`).
    - Set the default model:
    Supported providers (starter set)
    - [OpenAI (API + Codex)](/providers/openai)
    - [Anthropic (API + Claude Code CLI)](/providers/anthropic)
    - [OpenRouter](/providers/openrouter)
    - [Vercel AI Gateway](/providers/vercel-ai-gateway)
    - [Moonshot AI (Kimi + Kimi Code)](/providers/moonshot)
    - [Synthetic](/providers/synthetic)
    - [OpenCode Zen](/providers/opencode)
    - [Z.AI](/providers/zai)
    - [GLM models](/providers/glm)
    - [MiniMax](/providers/minimax)
    - [Venius (Venice AI)](/providers/venice)
    - [Amazon Bedrock](/bedrock)
    For the full provider catalog (xAI, Groq, Mistral, etc.) and advanced configuration, see [Model providers](/concepts/model-providers).
  Ex:
  - ID: EX-PROVIDERS-MODELS-0570B133BD
    Ctx: Copy
    Body: |-
      {
      agents: { defaults: { model: { primary: "anthropic/claude-opus-4-5" } } }
      }
- ID: PROVIDERS-MOONSHOT
  Src:
    File: output/providers/moonshot.md
    URL: https://docs.molt.bot/providers/moonshot
  Facts: |-
    H1: Moonshot - Moltbot
    Providers
    H1: Moonshot
    Moonshot AI (Kimi)
    Moonshot provides the Kimi API with OpenAI-compatible endpoints. Configure the provider and set the default model to `moonshot/kimi-k2.5`, or use Kimi Code with `kimi-code/kimi-for-coding`. Current Kimi K2 model IDs:
    - `kimi-k2.5`
    - `kimi-k2-0905-preview`
    - `kimi-k2-turbo-preview`
    - `kimi-k2-thinking`
    - `kimi-k2-thinking-turbo`
    Kimi Code:
    Note: Moonshot and Kimi Code are separate providers. Keys are not interchangeable, endpoints differ, and model refs differ (Moonshot uses `moonshot/...`, Kimi Code uses `kimi-code/...`).
    Config snippet (Moonshot API)
    Kimi Code
    Notes
    - Moonshot model refs use `moonshot/<modelId>`. Kimi Code model refs use `kimi-code/<modelId>`.
    - Override pricing and context metadata in `models.providers` if needed.
    - If Moonshot publishes different context limits for a model, adjust `contextWindow` accordingly.
    - Use `https://api.moonshot.cn/v1` if you need the China endpoint.
  Ex:
  - ID: EX-PROVIDERS-MOONSHOT-DFEFDE87A2
    Ctx: Copy
    Body: moltbot onboard --auth-choice moonshot-api-key
  - ID: EX-PROVIDERS-MOONSHOT-1AACB827A2
    Ctx: Copy
    Body: moltbot onboard --auth-choice kimi-code-api-key
  - ID: EX-PROVIDERS-MOONSHOT-AECD3924C5
    Ctx: Copy
    Body: |-
      {
      env: { MOONSHOT_API_KEY: "sk-..." },
      agents: {
      defaults: {
      model: { primary: "moonshot/kimi-k2.5" },
      models: {
      // moonshot-kimi-k2-aliases:start
      "moonshot/kimi-k2.5": { alias: "Kimi K2.5" },
      "moonshot/kimi-k2-0905-preview": { alias: "Kimi K2" },
      "moonshot/kimi-k2-turbo-preview": { alias: "Kimi K2 Turbo" },
      "moonshot/kimi-k2-thinking": { alias: "Kimi K2 Thinking" },
      "moonshot/kimi-k2-thinking-turbo": { alias: "Kimi K2 Thinking Turbo" }
      // moonshot-kimi-k2-aliases:end
      }
      }
      },
      models: {
      mode: "merge",
      providers: {
      moonshot: {
      baseUrl: "https://api.moonshot.ai/v1",
      apiKey: "${MOONSHOT_API_KEY}",
      api: "openai-completions",
      models: [
      // moonshot-kimi-k2-models:start
      {
      id: "kimi-k2.5",
      name: "Kimi K2.5",
      reasoning: false,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 256000,
      maxTokens: 8192
      },
      {
      id: "kimi-k2-0905-preview",
      name: "Kimi K2 0905 Preview",
      reasoning: false,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 256000,
      maxTokens: 8192
      },
      {
      id: "kimi-k2-turbo-preview",
      name: "Kimi K2 Turbo",
      reasoning: false,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 256000,
      maxTokens: 8192
      },
      {
      id: "kimi-k2-thinking",
      name: "Kimi K2 Thinking",
      reasoning: true,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 256000,
      maxTokens: 8192
      },
      {
      id: "kimi-k2-thinking-turbo",
      name: "Kimi K2 Thinking Turbo",
      reasoning: true,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 256000,
      maxTokens: 8192
      }
      // moonshot-kimi-k2-models:end
      ]
      }
      }
      }
      }
  - ID: EX-PROVIDERS-MOONSHOT-5BCC547378
    Ctx: Copy
    Body: |-
      {
      env: { KIMICODE_API_KEY: "sk-..." },
      agents: {
      defaults: {
      model: { primary: "kimi-code/kimi-for-coding" },
      models: {
      "kimi-code/kimi-for-coding": { alias: "Kimi Code" }
      }
      }
      },
      models: {
      mode: "merge",
      providers: {
      "kimi-code": {
      baseUrl: "https://api.kimi.com/coding/v1",
      apiKey: "${KIMICODE_API_KEY}",
      api: "openai-completions",
      models: [
      {
      id: "kimi-for-coding",
      name: "Kimi For Coding",
      reasoning: true,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 262144,
      maxTokens: 32768,
      headers: { "User-Agent": "KimiCLI/0.77" },
      compat: { supportsDeveloperRole: false }
      }
      ]
      }
      }
      }
      }
- ID: PROVIDERS-OPENAI
  Src:
    File: output/providers/openai.md
    URL: https://docs.molt.bot/providers/openai
  Facts: |-
    H1: Openai - Moltbot
    Providers
    H1: Openai
    OpenAI
    OpenAI provides developer APIs for GPT models. Codex supports **ChatGPT sign-in** for subscription access or **API key** sign-in for usage-based access. Codex cloud requires ChatGPT sign-in.
    Option A: OpenAI API key (OpenAI Platform)
    **Best for:** direct API access and usage-based billing. Get your API key from the OpenAI dashboard.
    CLI setup
    Config snippet
    Option B: OpenAI Code (Codex) subscription
    **Best for:** using ChatGPT/Codex subscription access instead of an API key. Codex cloud requires ChatGPT sign-in, while the Codex CLI supports ChatGPT or API key sign-in.
    CLI setup
    Config snippet
    Notes
    - Model refs always use `provider/model` (see [/concepts/models](/concepts/models)).
    - Auth details + reuse rules are in [/concepts/oauth](/concepts/oauth).
  Ex:
  - ID: EX-PROVIDERS-OPENAI-DB6B67767B
    Ctx: Copy
    Body: |-
      moltbot onboard --auth-choice openai-api-key
      # or non-interactive
      moltbot onboard --openai-api-key "$OPENAI_API_KEY"
  - ID: EX-PROVIDERS-OPENAI-BE626E3B00
    Ctx: Copy
    Body: |-
      {
      env: { OPENAI_API_KEY: "sk-..." },
      agents: { defaults: { model: { primary: "openai/gpt-5.2" } } }
      }
  - ID: EX-PROVIDERS-OPENAI-FADB41DDBF
    Ctx: Copy
    Body: |-
      # Run Codex OAuth in the wizard
      moltbot onboard --auth-choice openai-codex
  - ID: EX-PROVIDERS-OPENAI-C833AFD83E
    Body: |-
      # Or run OAuth directly
      moltbot models auth login --provider openai-codex
  - ID: EX-PROVIDERS-OPENAI-408335928C
    Ctx: Copy
    Body: |-
      {
      agents: { defaults: { model: { primary: "openai-codex/gpt-5.2" } } }
      }
- ID: PROVIDERS-OPENCODE
  Src:
    File: output/providers/opencode.md
    URL: https://docs.molt.bot/providers/opencode
  Facts: |-
    H1: Opencode - Moltbot
    Providers
    H1: Opencode
    OpenCode Zen
    OpenCode Zen is a **curated list of models** recommended by the OpenCode team for coding agents. It is an optional, hosted model access path that uses an API key and the `opencode` provider. Zen is currently in beta.
    CLI setup
    Config snippet
    Notes
    - `OPENCODE_ZEN_API_KEY` is also supported.
    - You sign in to Zen, add billing details, and copy your API key.
    - OpenCode Zen bills per request; check the OpenCode dashboard for details.
  Ex:
  - ID: EX-PROVIDERS-OPENCODE-3987576A47
    Ctx: Copy
    Body: |-
      moltbot onboard --auth-choice opencode-zen
      # or non-interactive
      moltbot onboard --opencode-zen-api-key "$OPENCODE_API_KEY"
  - ID: EX-PROVIDERS-OPENCODE-24C2DFBE10
    Ctx: Copy
    Body: |-
      {
      env: { OPENCODE_API_KEY: "sk-..." },
      agents: { defaults: { model: { primary: "opencode/claude-opus-4-5" } } }
      }
- ID: PROVIDERS-OPENROUTER
  Src:
    File: output/providers/openrouter.md
    URL: https://docs.molt.bot/providers/openrouter
  Facts: |-
    H1: Openrouter - Moltbot
    Providers
    H1: Openrouter
    OpenRouter
    OpenRouter provides a **unified API** that routes requests to many models behind a single endpoint and API key. It is OpenAI-compatible, so most OpenAI SDKs work by switching the base URL.
    CLI setup
    Config snippet
    Notes
    - Model refs are `openrouter/<provider>/<model>`.
    - For more model/provider options, see [/concepts/model-providers](/concepts/model-providers).
    - OpenRouter uses a Bearer token with your API key under the hood.
  Ex:
  - ID: EX-PROVIDERS-OPENROUTER-3CA68F2AB1
    Ctx: Copy
    Body: moltbot onboard --auth-choice apiKey --token-provider openrouter --token "$OPENROUTER_API_KEY"
  - ID: EX-PROVIDERS-OPENROUTER-A14225F0DF
    Ctx: Copy
    Body: |-
      {
      env: { OPENROUTER_API_KEY: "sk-or-..." },
      agents: {
      defaults: {
      model: { primary: "openrouter/anthropic/claude-sonnet-4-5" }
      }
      }
      }
- ID: PROVIDERS-SYNTHETIC
  Src:
    File: output/providers/synthetic.md
    URL: https://docs.molt.bot/providers/synthetic
  Facts: |-
    H1: Synthetic - Moltbot
    Providers
    H1: Synthetic
    Synthetic
    Synthetic exposes Anthropic-compatible endpoints. Moltbot registers it as the `synthetic` provider and uses the Anthropic Messages API.
    Quick setup
    - Set `SYNTHETIC_API_KEY` (or run the wizard below).
    - Run onboarding:
    The default model is set to:
    Config example
    Note: Moltbot's Anthropic client appends `/v1` to the base URL, so use `https://api.synthetic.new/anthropic` (not `/anthropic/v1`). If Synthetic changes its base URL, override `models.providers.synthetic.baseUrl`.
    Model catalog
    All models below use cost `0` (input/output/cache).
    Notes
    - Model refs use `synthetic/<modelId>`.
    - If you enable a model allowlist (`agents.defaults.models`), add every model you plan to use.
    - See [Model providers](/concepts/model-providers) for provider rules.
  Tables: |-
    Model ID| Context window| Max tokens| Reasoning| Input
    ---|---|---|---|---
    `hf:MiniMaxAI/MiniMax-M2.1`| 192000| 65536| false| text
    `hf:moonshotai/Kimi-K2-Thinking`| 256000| 8192| true| text
    `hf:zai-org/GLM-4.7`| 198000| 128000| false| text
    `hf:deepseek-ai/DeepSeek-R1-0528`| 128000| 8192| false| text
    `hf:deepseek-ai/DeepSeek-V3-0324`| 128000| 8192| false| text
    `hf:deepseek-ai/DeepSeek-V3.1`| 128000| 8192| false| text
    `hf:deepseek-ai/DeepSeek-V3.1-Terminus`| 128000| 8192| false| text
    `hf:deepseek-ai/DeepSeek-V3.2`| 159000| 8192| false| text
    `hf:meta-llama/Llama-3.3-70B-Instruct`| 128000| 8192| false| text
    `hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8`| 524000| 8192| false| text
    `hf:moonshotai/Kimi-K2-Instruct-0905`| 256000| 8192| false| text
    `hf:openai/gpt-oss-120b`| 128000| 8192| false| text
    `hf:Qwen/Qwen3-235B-A22B-Instruct-2507`| 256000| 8192| false| text
    `hf:Qwen/Qwen3-Coder-480B-A35B-Instruct`| 256000| 8192| false| text
    `hf:Qwen/Qwen3-VL-235B-A22B-Instruct`| 250000| 8192| false| text + image
    `hf:zai-org/GLM-4.5`| 128000| 128000| false| text
    `hf:zai-org/GLM-4.6`| 198000| 128000| false| text
    `hf:deepseek-ai/DeepSeek-V3`| 128000| 8192| false| text
    `hf:Qwen/Qwen3-235B-A22B-Thinking-2507`| 256000| 8192| true| text
  Ex:
  - ID: EX-PROVIDERS-SYNTHETIC-3A1C315278
    Ctx: Copy
    Body: moltbot onboard --auth-choice synthetic-api-key
  - ID: EX-PROVIDERS-SYNTHETIC-0758BA20B7
    Ctx: Copy
    Body: synthetic/hf:MiniMaxAI/MiniMax-M2.1
  - ID: EX-PROVIDERS-SYNTHETIC-68C5D16C82
    Ctx: Copy
    Body: |-
      {
      env: { SYNTHETIC_API_KEY: "sk-..." },
      agents: {
      defaults: {
      model: { primary: "synthetic/hf:MiniMaxAI/MiniMax-M2.1" },
      models: { "synthetic/hf:MiniMaxAI/MiniMax-M2.1": { alias: "MiniMax M2.1" } }
      }
      },
      models: {
      mode: "merge",
      providers: {
      synthetic: {
      baseUrl: "https://api.synthetic.new/anthropic",
      apiKey: "${SYNTHETIC_API_KEY}",
      api: "anthropic-messages",
      models: [
      {
      id: "hf:MiniMaxAI/MiniMax-M2.1",
      name: "MiniMax M2.1",
      reasoning: false,
      input: ["text"],
      cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
      contextWindow: 192000,
      maxTokens: 65536
      }
      ]
      }
      }
      }
      }
- ID: PROVIDERS-VERCEL-AI-GATEWAY
  Src:
    File: output/providers/vercel-ai-gateway.md
    URL: https://docs.molt.bot/providers/vercel-ai-gateway
  Facts: |-
    H1: Vercel AI Gateway - Moltbot
    Providers
    H1: Vercel AI Gateway
    Vercel AI Gateway
    The [Vercel AI Gateway](https://vercel.com/ai-gateway) provides a unified API to access hundreds of models through a single endpoint.
    - Provider: `vercel-ai-gateway`
    - Auth: `AI_GATEWAY_API_KEY`
    - API: Anthropic Messages compatible
    Quick start
    - Set the API key (recommended: store it for the Gateway):
    - Set a default model:
    Non-interactive example
    Environment note
    If the Gateway runs as a daemon (launchd/systemd), make sure `AI_GATEWAY_API_KEY` is available to that process (for example, in `~/.clawdbot/.env` or via `env.shellEnv`).
  Ex:
  - ID: EX-PROVIDERS-VERCEL-AI-GATEWAY-2BE1D43104
    Ctx: Copy
    Body: moltbot onboard --auth-choice ai-gateway-api-key
  - ID: EX-PROVIDERS-VERCEL-AI-GATEWAY-4609BE1D7D
    Ctx: Copy
    Body: |-
      {
      agents: {
      defaults: {
      model: { primary: "vercel-ai-gateway/anthropic/claude-opus-4.5" }
      }
      }
      }
  - ID: EX-PROVIDERS-VERCEL-AI-GATEWAY-13B4370B2D
    Ctx: Copy
    Body: |-
      moltbot onboard --non-interactive \
      --mode local \
      --auth-choice ai-gateway-api-key \
      --ai-gateway-api-key "$AI_GATEWAY_API_KEY"
- ID: PROVIDERS-ZAI
  Src:
    File: output/providers/zai.md
    URL: https://docs.molt.bot/providers/zai
  Facts: |-
    H1: Zai - Moltbot
    Providers
    H1: Zai
    Z.AI
    Z.AI is the API platform for **GLM** models. It provides REST APIs for GLM and uses API keys for authentication. Create your API key in the Z.AI console. Moltbot uses the `zai` provider with a Z.AI API key.
    CLI setup
    Config snippet
    Notes
    - GLM models are available as `zai/<model>` (example: `zai/glm-4.7`).
    - See [/providers/glm](/providers/glm) for the model family overview.
    - Z.AI uses Bearer auth with your API key.
  Ex:
  - ID: EX-PROVIDERS-ZAI-2187E57B8B
    Ctx: Copy
    Body: |-
      moltbot onboard --auth-choice zai-api-key
      # or non-interactive
      moltbot onboard --zai-api-key "$ZAI_API_KEY"
  - ID: EX-PROVIDERS-ZAI-98C4785754
    Ctx: Copy
    Body: |-
      {
      env: { ZAI_API_KEY: "sk-..." },
      agents: { defaults: { model: { primary: "zai/glm-4.7" } } }
      }
- ID: WEB-CONTROL-UI
  Src:
    File: output/web/control-ui.md
    URL: https://docs.molt.bot/web/control-ui
  Facts: |-
    H1: Control ui - Moltbot
    Web & Interfaces
    H1: Control ui
    Control UI (browser)
    The Control UI is a small **Vite + Lit** single-page app served by the Gateway:
    - default: `http://<host>:18789/`
    - optional prefix: set `gateway.controlUi.basePath` (e.g. `/moltbot`)
    It speaks **directly to the Gateway WebSocket** on the same port.
    Quick open (local)
    If the Gateway is running on the same computer, open:
    - <http://127.0.0.1:18789/> (or <http://localhost:18789/>)
    If the page fails to load, start the Gateway first: `moltbot gateway`. Auth is supplied during the WebSocket handshake via:
    - `connect.params.auth.token`
    - `connect.params.auth.password` The dashboard settings panel lets you store a token; passwords are not persisted. The onboarding wizard generates a gateway token by default, so paste it here on first connect.
    What it can do (today)
    - Chat with the model via Gateway WS (`chat.history`, `chat.send`, `chat.abort`, `chat.inject`)
    - Stream tool calls + live tool output cards in Chat (agent events)
    - Channels: WhatsApp/Telegram/Discord/Slack + plugin channels (Mattermost, etc.) status + QR login + per-channel config (`channels.status`, `web.login.*`, `config.patch`)
    - Instances: presence list + refresh (`system-presence`)
    - Sessions: list + per-session thinking/verbose overrides (`sessions.list`, `sessions.patch`)
    - Cron jobs: list/add/run/enable/disable + run history (`cron.*`)
    - Skills: status, enable/disable, install, API key updates (`skills.*`)
    - Nodes: list + caps (`node.list`)
    - Exec approvals: edit gateway or node allowlists + ask policy for `exec host=gateway/node` (`exec.approvals.*`)
    - Config: view/edit `~/.clawdbot/moltbot.json` (`config.get`, `config.set`)
    - Config: apply + restart with validation (`config.apply`) and wake the last active session
    - Config writes include a base-hash guard to prevent clobbering concurrent edits
    - Config schema + form rendering (`config.schema`, including plugin + channel schemas); Raw JSON editor remains available
    - Debug: status/health/models snapshots + event log + manual RPC calls (`status`, `health`, `models.list`)
    - Logs: live tail of gateway file logs with filter/export (`logs.tail`)
    - Update: run a package/git update + restart (`update.run`) with a restart report
    Chat behavior
    - `chat.send` is **non-blocking** : it acks immediately with `{ runId, status: "started" }` and the response streams via `chat` events.
    - Re-sending with the same `idempotencyKey` returns `{ status: "in_flight" }` while running, and `{ status: "ok" }` after completion.
    - `chat.inject` appends an assistant note to the session transcript and broadcasts a `chat` event for UI-only updates (no agent run, no channel delivery).
    - Stop:
    - Click **Stop** (calls `chat.abort`)
    - Type `/stop` (or `stop|esc|abort|wait|exit|interrupt`) to abort out-of-band
    - `chat.abort` supports `{ sessionKey }` (no `runId`) to abort all active runs for that session
    Tailnet access (recommended)
    Integrated Tailscale Serve (preferred)
    Keep the Gateway on loopback and let Tailscale Serve proxy it with HTTPS:
    Open:
    - `https://<magicdns>/` (or your configured `gateway.controlUi.basePath`)
    By default, Serve requests can authenticate via Tailscale identity headers (`tailscale-user-login`) when `gateway.auth.allowTailscale` is `true`. Moltbot verifies the identity by resolving the `x-forwarded-for` address with `tailscale whois` and matching it to the header, and only accepts these when the request hits loopback with Tailscale's `x-forwarded-*` headers. Set `gateway.auth.allowTailscale: false` (or force `gateway.auth.mode: "password"`) if you want to require a token/password even for Serve traffic.
    Bind to tailnet + token
    Then open:
    - `http://<tailscale-ip>:18789/` (or your configured `gateway.controlUi.basePath`)
    Paste the token into the UI settings (sent as `connect.params.auth.token`).
    Insecure HTTP
    If you open the dashboard over plain HTTP (`http://<lan-ip>` or `http://<tailscale-ip>`), the browser runs in a **non-secure context** and blocks WebCrypto. By default, Moltbot **blocks** Control UI connections without device identity. **Recommended fix:** use HTTPS (Tailscale Serve) or open the UI locally:
    - `https://<magicdns>/` (Serve)
    - `http://127.0.0.1:18789/` (on the gateway host)
    **Downgrade example (token-only over HTTP):**
    This disables device identity + pairing for the Control UI (even on HTTPS). Use only if you trust the network. See [Tailscale](/gateway/tailscale) for HTTPS setup guidance.
    Building the UI
    The Gateway serves static files from `dist/control-ui`. Build them with:
    Optional absolute base (when you want fixed asset URLs):
    For local development (separate dev server):
    Then point the UI at your Gateway WS URL (e.g. `ws://127.0.0.1:18789`).
    Debugging/testing: dev server + remote Gateway
    The Control UI is static files; the WebSocket target is configurable and can be different from the HTTP origin. This is handy when you want the Vite dev server locally but the Gateway runs elsewhere.
    - Start the UI dev server: `pnpm ui:dev`
    - Open a URL like:
    Optional one-time auth (if needed):
    Notes:
    - `gatewayUrl` is stored in localStorage after load and removed from the URL.
    - `token` is stored in localStorage; `password` is kept in memory only.
    - Use `wss://` when the Gateway is behind TLS (Tailscale Serve, HTTPS proxy, etc.).
    Remote access setup details: [Remote access](/gateway/remote).
  Ex:
  - ID: EX-WEB-CONTROL-UI-6DB652DF01
    Ctx: Copy
    Body: moltbot gateway --tailscale serve
  - ID: EX-WEB-CONTROL-UI-580D983E3D
    Ctx: Copy
    Body: moltbot gateway --bind tailnet --token "$(openssl rand -hex 32)"
  - ID: EX-WEB-CONTROL-UI-E743D1CE9B
    Ctx: Copy
    Body: |-
      {
      gateway: {
      controlUi: { allowInsecureAuth: true },
      bind: "tailnet",
      auth: { mode: "token", token: "replace-me" }
      }
      }
  - ID: EX-WEB-CONTROL-UI-07299886DF
    Ctx: Copy
    Body: 'pnpm ui:build # auto-installs UI deps on first run'
  - ID: EX-WEB-CONTROL-UI-B2927C0569
    Ctx: Copy
    Body: CLAWDBOT_CONTROL_UI_BASE_PATH=/moltbot/ pnpm ui:build
  - ID: EX-WEB-CONTROL-UI-4519DF3DAC
    Ctx: Copy
    Body: 'pnpm ui:dev # auto-installs UI deps on first run'
  - ID: EX-WEB-CONTROL-UI-1913E68A02
    Ctx: Copy
    Body: http://localhost:5173/?gatewayUrl=ws://<gateway-host>:18789
  - ID: EX-WEB-CONTROL-UI-D5D5B7DB8B
    Ctx: Copy
    Body: http://localhost:5173/?gatewayUrl=wss://<gateway-host>:18789&token=<gateway-token>
- ID: WEB-DASHBOARD
  Src:
    File: output/web/dashboard.md
    URL: https://docs.molt.bot/web/dashboard
  Facts: |-
    H1: Dashboard - Moltbot
    Web & Interfaces
    H1: Dashboard
    Dashboard (Control UI)
    The Gateway dashboard is the browser Control UI served at `/` by default (override with `gateway.controlUi.basePath`). Quick open (local Gateway):
    - <http://127.0.0.1:18789/> (or <http://localhost:18789/>)
    Key references:
    - [Control UI](/web/control-ui) for usage and UI capabilities.
    - [Tailscale](/gateway/tailscale) for Serve/Funnel automation.
    - [Web surfaces](/web) for bind modes and security notes.
    Authentication is enforced at the WebSocket handshake via `connect.params.auth` (token or password). See `gateway.auth` in [Gateway configuration](/gateway/configuration). Security note: the Control UI is an **admin surface** (chat, config, exec approvals). Do not expose it publicly. The UI stores the token in `localStorage` after first load. Prefer localhost, Tailscale Serve, or an SSH tunnel.
    Fast path (recommended)
    - After onboarding, the CLI now auto-opens the dashboard with your token and prints the same tokenized link.
    - Re-open anytime: `moltbot dashboard` (copies link, opens browser if possible, shows SSH hint if headless).
    - The token stays local (query param only); the UI strips it after first load and saves it in localStorage.
    Token basics (local vs remote)
    - **Localhost** : open `http://127.0.0.1:18789/`. If you see "unauthorized," run `moltbot dashboard` and use the tokenized link (`?token=...`).
    - **Token source** : `gateway.auth.token` (or `CLAWDBOT_GATEWAY_TOKEN`); the UI stores it after first load.
    - **Not localhost** : use Tailscale Serve (tokenless if `gateway.auth.allowTailscale: true`), tailnet bind with a token, or an SSH tunnel. See [Web surfaces](/web).
    If you see "unauthorized" / 1008
    - Run `moltbot dashboard` to get a fresh tokenized link.
    - Ensure the gateway is reachable (local: `moltbot status`; remote: SSH tunnel `ssh -N -L 18789:127.0.0.1:18789 user@host` then open `http://127.0.0.1:18789/?token=...`).
    - In the dashboard settings, paste the same token you configured in `gateway.auth.token` (or `CLAWDBOT_GATEWAY_TOKEN`).
- ID: WEB-WEBCHAT
  Src:
    File: output/web/webchat.md
    URL: https://docs.molt.bot/web/webchat
  Facts: |-
    H1: Webchat - Moltbot
    Web & Interfaces
    H1: Webchat
    WebChat (Gateway WebSocket UI)
    Status: the macOS/iOS SwiftUI chat UI talks directly to the Gateway WebSocket.
    What it is
    - A native chat UI for the gateway (no embedded browser and no local static server).
    - Uses the same sessions and routing rules as other channels.
    - Deterministic routing: replies always go back to WebChat.
    Quick start
    - Start the gateway.
    - Open the WebChat UI (macOS/iOS app) or the Control UI chat tab.
    - Ensure gateway auth is configured (required by default, even on loopback).
    How it works (behavior)
    - The UI connects to the Gateway WebSocket and uses `chat.history`, `chat.send`, and `chat.inject`.
    - `chat.inject` appends an assistant note directly to the transcript and broadcasts it to the UI (no agent run).
    - History is always fetched from the gateway (no local file watching).
    - If the gateway is unreachable, WebChat is read-only.
    Remote use
    - Remote mode tunnels the gateway WebSocket over SSH/Tailscale.
    - You do not need to run a separate WebChat server.
    Configuration reference (WebChat)
    Full configuration: [Configuration](/gateway/configuration) Channel options:
    - No dedicated `webchat.*` block. WebChat uses the gateway endpoint + auth settings below.
    Related global options:
    - `gateway.port`, `gateway.bind`: WebSocket host/port.
    - `gateway.auth.mode`, `gateway.auth.token`, `gateway.auth.password`: WebSocket auth.
    - `gateway.remote.url`, `gateway.remote.token`, `gateway.remote.password`: remote gateway target.
    - `session.*`: session storage and main key defaults.
Semantic_FS_Anchors:
  Generated_By: fix_koda_semantic_fs.py
  Generated_At: '2026-01-29'
  Missing_Backticks: |-
    (api) => { ... }
    --command-timeout
    --cwd
    --delivery <system|overlay|auto>
    --display-name
    --env KEY=VAL
    --needs-screen-recording
    --priority <passive|active|timeSensitive>
    --screen <index>
    --set-default
    --tls
    --tls-fingerprint
    --x/--y/--width/--height
    .ts
    /MyStatus
    /channels/<id>
    /mystatus
    /providers/*
    32000
    4096
    <moltbot>/extensions/*
    <workspace>/.clawdbot/extensions/*.ts
    <workspace>/.clawdbot/extensions/*/index.ts
    @moltbot/*
    @moltbot/matrix
    @moltbot/msteams
    @moltbot/nostr
    AWS_ACCESS_KEY_ID
    AWS_BEARER_TOKEN_BEDROCK
    AWS_DEFAULT_REGION
    AWS_PROFILE
    AWS_PROFILE=default
    AWS_REGION
    AWS_SECRET_ACCESS_KEY
    AmazonBedrockFullAccess
    CLAWDBOT_MPM_CATALOG_PATHS
    CLAWDBOT_NODE_EXEC_FALLBACK=0
    CLAWDBOT_NODE_EXEC_HOST=app
    CLAWDBOT_PLUGIN_CATALOG_PATHS
    HOOK.md
    Mode set to: ${mode}
    Plugin is running! Channel: ${ctx.channel}
    ProviderAuthContext
    SYSTEM_RUN_DENIED
    acceptsArgs
    acceptsArgs: true
    accessibility
    actions
    amazon-bedrock
    api.registerChannel({ plugin })
    api.registerProvider(...)
    api.runtime
    bedrock-converse-stream
    bedrock:InvokeModel
    bedrock:InvokeModelWithResponseStream
    bedrock:ListFoundationModels
    canvas eval
    canvas present
    canvas.snapshot
    channels.<id>
    channels.<id>.accounts.<accountId>
    commandBody
    config.listAccountIds
    config.resolveAccount
    configPatch
    configSchema
    defaultContextWindow
    defaultMaxTokens
    defaultModel
    dist/index.js
    entries.<id>
    exec host=node
    extensions/voice-call/README.md
    gateway.tailscale.mode: "funnel"
    github-copilot
    google-antigravity-auth
    google-gemini-cli-auth
    handler
    handler.ts
    hooks.enabled=true
    host=node
    isAuthorizedSender
    kind: "memory"
    load.paths
    mentions
    meta.aliases
    meta.blurb
    meta.detailLabel
    meta.docsPath
    meta.label
    meta.preferOver
    meta.selectionLabel
    meta.systemImage
    models.bedrockDiscovery
    moltbot hooks
    moltbot hooks list
    moltbot models auth login --provider <id> [--method <id>]
    moltbot node install
    moltbot node run
    moltbot nodes pending/approve/reject
    moltbot nodes rename --node <id|name|ip> --name "Build Node"
    moltbot nodes …
    moltbot plugins enable <id>
    moltbot plugins install <npm-spec>
    moltbot voicecall start|status
    moltbot.channel
    moltbot.extensions
    moltbot.install
    moltbot.plugin.json
    name/<fileBase>
    node.describe
    node.pair.*
    node_modules
    nodes status
    npm pack
    oauth.createVpsAwareHandlers
    openUrl
    outbound.deliveryMode
    outbound.sendText
    package.json
    plugin:<id>
    pluginId.action
    plugins update
    plugins.allow
    plugins.entries.<id>
    plugins.entries.<id>.config
    plugins.entries.<id>.config.<field>
    plugins.entries.<id>.enabled
    plugins.installs
    plugins.load.paths
    plugins.slots
    plugins.slots.memory
    plugins.slots.memory = "memory-lancedb"
    prompter
    provider: "log"
    providerFilter
    qwen-portal-auth
    refreshInterval
    region
    requireAuth
    reset
    role: "node"
    role: node
    screen.record
    screenRecording
    senderId
    skills/<name>/SKILL.md
    slots
    sms.send
    snake_case
    src/**
    src/plugins/voice-call.plugin.test.ts
    statusCallbackUrl
    system.*
    system.execApprovals.get/set
    system.notify
    system.run
    system.which
    threading
    twilio.accountSid/authToken/from
    twimlUrl
    uiHints
    us-east-1
    voicecall.start
    { "entries": [ { "name": "@scope/pkg", "moltbot": { "channel": {...}, "install": {...} } } ] }
    { format, base64 }
    { id, name, configSchema, register(api) { ... } }
    { text: string }
    ~/.../voice-call.ts
    ~/.clawdbot/exec-approvals.json
    ~/.clawdbot/extensions/*.ts
    ~/.clawdbot/extensions/*/index.ts
    ~/.clawdbot/extensions/<id>/
    ~/.clawdbot/mpm/catalog.json
    ~/.clawdbot/mpm/plugins.json
    ~/.clawdbot/node.json
    ~/.clawdbot/plugins/catalog.json
  Missing_Code_Blocks_Body: |-
    api.registerProvider({
    id: "acme",
    label: "AcmeAI",
    auth: [
    {
    id: "oauth",
    label: "OAuth",
    kind: "oauth",
    run: async (ctx) => {
    // Run OAuth flow and return auth profiles.
    return {
    profiles: [
    {
    profileId: "acme:default",
    credential: {
    type: "oauth",
    provider: "acme",
    access: "...",
    refresh: "...",
    expires: Date.now() + 3600 * 1000,
    },
    },
    ],
    defaultModel: "acme/opus-1",
    };
    },
    },
    ],
    });

    {
    "id": "my-plugin",
    "configSchema": {
    "type": "object",
    "additionalProperties": false,
    "properties": {
    "apiKey": { "type": "string" },
    "region": { "type": "string" }
    }
    },
    "uiHints": {
    "apiKey": { "label": "API Key", "sensitive": true },
    "region": { "label": "Region", "placeholder": "us-east-1" }
    }
    }

    {
    "name": "my-pack",
    "moltbot": {
    "extensions": ["./src/safety.ts", "./src/tools.ts"]
    }
    }

    moltbot config set tools.exec.host node
    moltbot config set tools.exec.security allowlist
    moltbot config set tools.exec.node "<id-or-name>"

    {
    channels: {
    acmechat: {
    accounts: {
    default: { token: "ACME_TOKEN", enabled: true }
    }
    }
    }
    }

    moltbot devices list
    moltbot devices approve <requestId>
    moltbot devices reject <requestId>
    moltbot nodes status
    moltbot nodes describe --node <idOrNameOrIp>

    {
    models: {
    providers: {
    "amazon-bedrock": {
    baseUrl: "https://bedrock-runtime.us-east-1.amazonaws.com",
    api: "bedrock-converse-stream",
    auth: "aws-sdk",
    models: [
    {
    id: "anthropic.claude-opus-4-5-20251101-v1:0",
    name: "Claude Opus 4.5 (Bedrock)",
    reasoning: true,
    input: ["text", "image"],
    cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
    contextWindow: 200000,
    maxTokens: 8192
    }
    ]
    }
    }
    },
    agents: {
    defaults: {
    model: { primary: "amazon-bedrock/anthropic.claude-opus-4-5-20251101-v1:0" }
    }
    }
    }

    moltbot node install --host <gateway-host> --port 18789 --display-name "Build Node"
    moltbot node restart

    moltbot nodes canvas present --node <idOrNameOrIp> --target https://example.com
    moltbot nodes canvas hide --node <idOrNameOrIp>
    moltbot nodes canvas navigate https://example.com --node <idOrNameOrIp>
    moltbot nodes canvas eval --node <idOrNameOrIp> --js "document.title"

    # 5. Verify models are discovered
    moltbot models list

    moltbot nodes invoke --node <idOrNameOrIp> --command canvas.eval --params '{"javaScript":"location.href"}'

    moltbot node run --host <gateway-host> --port 18789

    {
    "name": "@moltbot/nextcloud-talk",
    "moltbot": {
    "extensions": ["./index.ts"],
    "channel": {
    "id": "nextcloud-talk",
    "label": "Nextcloud Talk",
    "selectionLabel": "Nextcloud Talk (self-hosted)",
    "docsPath": "/channels/nextcloud-talk",
    "docsLabel": "nextcloud-talk",
    "blurb": "Self-hosted chat via Nextcloud Talk webhook bots.",
    "order": 65,
    "aliases": ["nc-talk", "nc"]
    },
    "install": {
    "npmSpec": "@moltbot/nextcloud-talk",
    "localPath": "extensions/nextcloud-talk",
    "defaultChoice": "npm"
    }
    }
    }

    {
    models: {
    bedrockDiscovery: {
    enabled: true,
    region: "us-east-1",
    providerFilter: ["anthropic", "amazon"],
    refreshInterval: 3600,
    defaultContextWindow: 32000,
    defaultMaxTokens: 4096
    }
    }
    }

    /exec host=node security=allowlist node=<id-or-name>

    moltbot config set tools.exec.node "node-id-or-name"

    const plugin = {
    id: "acmechat",
    meta: {
    id: "acmechat",
    label: "AcmeChat",
    selectionLabel: "AcmeChat (API)",
    docsPath: "/channels/acmechat",
    blurb: "AcmeChat messaging channel.",
    aliases: ["acme"],
    },
    capabilities: { chatTypes: ["direct"] },
    config: {
    listAccountIds: (cfg) => Object.keys(cfg.channels?.acmechat?.accounts ?? {}),
    resolveAccount: (cfg, accountId) =>
    (cfg.channels?.acmechat?.accounts?.[accountId ?? "default"] ?? { accountId }),
    },
    outbound: {
    deliveryMode: "direct",
    sendText: async ({ text }) => {
    // deliver `text` to your channel here
    return { ok: true };
    },
    },
    };

    # 1. Create IAM role and instance profile
    aws iam create-role --role-name EC2-Bedrock-Access \
    --assume-role-policy-document '{
    "Version": "2012-10-17",
    "Statement": [{
    "Effect": "Allow",
    "Principal": {"Service": "ec2.amazonaws.com"},
    "Action": "sts:AssumeRole"
    }]
    }'

    moltbot config unset tools.exec.node
    moltbot config unset agents.list[0].tools.exec.node

    const myChannel = {
    id: "acmechat",
    meta: {
    id: "acmechat",
    label: "AcmeChat",
    selectionLabel: "AcmeChat (API)",
    docsPath: "/channels/acmechat",
    blurb: "demo channel plugin.",
    aliases: ["acme"],
    },
    capabilities: { chatTypes: ["direct"] },
    config: {
    listAccountIds: (cfg) => Object.keys(cfg.channels?.acmechat?.accounts ?? {}),
    resolveAccount: (cfg, accountId) =>
    (cfg.channels?.acmechat?.accounts?.[accountId ?? "default"] ?? { accountId }),
    },
    outbound: {
    deliveryMode: "direct",
    sendText: async () => ({ ok: true }),
    },
    };

    export default function register(api) {
    registerPluginHooksFromDir(api, "./hooks");
    }

    {
    gateway: {
    bind: "loopback",
    tailscale: { mode: "serve" }
    }
    }

    moltbot nodes screen record --node <idOrNameOrIp> --duration 10s --fps 10
    moltbot nodes screen record --node <idOrNameOrIp> --duration 10s --fps 10 --no-audio

    moltbot approvals allowlist add --node <id|name|ip> "/usr/bin/uname"
    moltbot approvals allowlist add --node <id|name|ip> "/usr/bin/sw_vers"

    {
    gateway: {
    bind: "loopback",
    tailscale: { mode: "funnel" },
    auth: { mode: "password" } // or CLAWDBOT_GATEWAY_PASSWORD
    }
    }

    const result = await api.runtime.tts.textToSpeechTelephony({
    text: "Hello from Moltbot",
    cfg: api.config,
    });

    moltbot nodes pending
    moltbot nodes approve <requestId>
    moltbot nodes list

    # Add to ~/.bashrc or your shell profile
    export AWS_PROFILE=default
    export AWS_REGION=us-east-1

    {
    gateway: {
    bind: "tailnet",
    controlUi: { enabled: true },
    auth: { mode: "token", token: "your-token" }
    }
    }

    moltbot nodes canvas a2ui push --node <idOrNameOrIp> --text "Hello"
    moltbot nodes canvas a2ui push --node <idOrNameOrIp> --jsonl ./payload.jsonl
    moltbot nodes canvas a2ui reset --node <idOrNameOrIp>

    import { registerPluginHooksFromDir } from "moltbot/plugin-sdk";

    {
    plugins: {
    enabled: true,
    allow: ["voice-call"],
    deny: ["untrusted-plugin"],
    load: { paths: ["~/Projects/oss/voice-call-extension"] },
    entries: {
    "voice-call": { enabled: true, config: { provider: "twilio" } }
    }
    }
    }

    export default function (api) {
    api.registerService({
    id: "my-service",
    start: () => api.logger.info("ready"),
    stop: () => api.logger.info("bye"),
    });
    }

    moltbot nodes camera clip --node <idOrNameOrIp> --duration 10s
    moltbot nodes camera clip --node <idOrNameOrIp> --duration 3000 --no-audio

    export default function (api) {
    api.registerCommand({
    name: "mystatus",
    description: "Show plugin status",
    handler: (ctx) => ({
    text: `Plugin is running! Channel: ${ctx.channel}`,
    }),
    });
    }

    # 3. On the EC2 instance, enable discovery
    moltbot config set models.bedrockDiscovery.enabled true
    moltbot config set models.bedrockDiscovery.region us-east-1

    api.registerCommand({
    name: "setmode",
    description: "Set plugin mode",
    acceptsArgs: true,
    requireAuth: true,
    handler: async (ctx) => {
    const mode = ctx.args?.trim() || "default";
    await saveMode(mode);
    return { text: `Mode set to: ${mode}` };
    },
    });

    moltbot nodes invoke --node <idOrNameOrIp> --command sms.send --params '{"to":"+15555550123","message":"Hello from Moltbot"}'

    export default function (api) {
    api.registerCli(({ program }) => {
    program.command("mycmd").action(() => {
    console.log("Hello");
    });
    }, { commands: ["mycmd"] });
    }

    moltbot plugins list
    moltbot plugins info <id>
    moltbot plugins install <path>                 # copy a local file/dir into ~/.clawdbot/extensions/<id>
    moltbot plugins install ./extensions/voice-call # relative path ok
    moltbot plugins install ./plugin.tgz           # install from a local tarball
    moltbot plugins install ./plugin.zip           # install from a local zip
    moltbot plugins install -l ./extensions/voice-call # link (no copy) for dev
    moltbot plugins install @moltbot/voice-call # install from npm
    moltbot plugins update <id>
    moltbot plugins update --all
    moltbot plugins enable <id>
    moltbot plugins disable <id>
    moltbot plugins doctor

    aws iam create-instance-profile --instance-profile-name EC2-Bedrock-Access
    aws iam add-role-to-instance-profile \
    --instance-profile-name EC2-Bedrock-Access \
    --role-name EC2-Bedrock-Access

    moltbot config get agents.list
    moltbot config set agents.list[0].tools.exec.node "node-id-or-name"

    {
    plugins: {
    slots: {
    memory: "memory-core" // or "none" to disable memory plugins
    }
    }
    }

    export AWS_ACCESS_KEY_ID="AKIA..."
    export AWS_SECRET_ACCESS_KEY="..."
    export AWS_REGION="us-east-1"
    # Optional:
    export AWS_SESSION_TOKEN="..."
    export AWS_PROFILE="your-profile"
    # Optional (Bedrock API key/bearer token):
    export AWS_BEARER_TOKEN_BEDROCK="..."

    moltbot nodes canvas snapshot --node <idOrNameOrIp> --format png
    moltbot nodes canvas snapshot --node <idOrNameOrIp> --format jpg --max-width 1200 --quality 0.9

    export default function (api) {
    api.registerChannel({ plugin: myChannel });
    }

    moltbot plugins list

    export default function (api) {
    api.registerChannel({ plugin });
    }

    aws iam attach-role-policy --role-name EC2-Bedrock-Access \
    --policy-arn arn:aws:iam::aws:policy/AmazonBedrockFullAccess

    moltbot node run --host <gateway-host> --port 18789 --display-name "Build Node"

    {
    gateway: {
    controlUi: { enabled: true, basePath: "/moltbot" } // basePath optional
    }
    }

    moltbot nodes run --node <idOrNameOrIp> -- echo "Hello from mac node"
    moltbot nodes notify --node <idOrNameOrIp> --title "Ping" --body "Gateway ready"

    moltbot nodes camera list --node <idOrNameOrIp>
    moltbot nodes camera snap --node <idOrNameOrIp>            # default: both facings (2 MEDIA lines)
    moltbot nodes camera snap --node <idOrNameOrIp> --facing front

    # 2. Attach to your EC2 instance
    aws ec2 associate-iam-instance-profile \
    --instance-id i-xxxxx \
    --iam-instance-profile Name=EC2-Bedrock-Access

    # 4. Set the workaround env vars
    echo 'export AWS_PROFILE=default' >> ~/.bashrc
    echo 'export AWS_REGION=us-east-1' >> ~/.bashrc
    source ~/.bashrc

    moltbot nodes location get --node <idOrNameOrIp>
    moltbot nodes location get --node <idOrNameOrIp> --accuracy precise --max-age 15000 --location-timeout 10000

    export default function (api) {
    api.registerGatewayMethod("myplugin.status", ({ respond }) => {
    respond(true, { ok: true });
    });
    }
