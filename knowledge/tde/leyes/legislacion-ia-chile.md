---
_manifest:
  urn: "urn:tde:kb:legislacion-ia-chile"
  provenance:
    created_by: FS
    created_at: '2026-02-26'
    source: "Análisis interno KODA — Proyecto de Ley IA Chile (boletines 16.821-19 / 15.869-19)"
version: 1.0.0
status: published
tags: [ley, inteligencia-artificial, ia, regulacion, riesgo, gobernanza, apdp, anci, tde, proyecto-ley]
lang: es
---

# Proyecto de Ley de Inteligencia Artificial — Chile

Análisis del proyecto de ley en trámite que regula sistemas de IA en Chile. Fusión de dos iniciativas: mensaje presidencial (boletín 16.821-19, 7 mayo 2024) y moción parlamentaria (boletín 15.869-19, 24 abril 2023).

## Antecedentes

### Iniciativas legislativas

| Iniciativa | Boletín | Fecha | Origen |
|---|---|---|---|
| Mensaje presidencial | 16.821-19 | 7 mayo 2024 | Ejecutivo, urgencia suma |
| Moción parlamentaria | 15.869-19 | 24 abril 2023 | Comisión de Futuro, Ciencia, Tecnología e Innovación |

### Contexto político-técnico

- **Moción**: regular sistemas de IA, robótica y tecnologías conexas
- **Mensaje**: abordar potencial de bienestar y competitividad de la IA frente a riesgos éticos; urgencia suma
- **Referentes internacionales**: Recomendación UNESCO 2021 (ética IA), Ley IA Unión Europea (enfoque riesgo), EEUU (autorregulación/compromisos voluntarios), China (algoritmos y contenido sintético)
- **Síntesis política**: impulsar IA responsable alineada con estándares internacionales y estrategia de transformación digital
- **Síntesis técnica**: incorporar principios éticos y lecciones comparadas para certezas regulatorias que respeten derechos fundamentales
- **Consulta judicial**: remitido a Corte Suprema el 8 mayo 2024; respuesta recibida 21 junio 2024
- **Aprobación**: unanimidad en general en Comisión especializada

## Estructura del proyecto

31 artículos permanentes + 3 transitorios, organizados en 9 títulos:

| N | Título |
|---|--------|
| I | Disposiciones generales (objeto, ámbito, definiciones, clasificación de riesgos) |
| II | Sistemas de riesgo inaceptable |
| III | Sistemas de IA de alto riesgo |
| IV | Sistemas de IA de riesgo limitado |
| V | Incidentes graves |
| VI | Gobernanza de IA |
| VII | Medidas de apoyo a la innovación |
| VIII | Confidencialidad, infracciones y sanciones |
| IX | Disposiciones finales y transitorias |

## Objeto y ámbito de aplicación

**Objeto**: promover creación, desarrollo, innovación e implementación de sistemas de IA al servicio del ser humano, coherente con principios democráticos y derechos fundamentales.

**Ámbito**: todos los actores de la cadena de valor (desarrolladores, proveedores, implementadores, importadores, distribuidores) cuando las salidas del sistema se usen en territorio nacional.

### Exclusiones

| Exclusión | Alcance |
|---|---|
| Defensa nacional | Sistemas desarrollados y usados con fines de defensa nacional |
| Investigación y desarrollo | Actividades previas a comercialización que respeten derechos fundamentales y no involucren pruebas en condiciones reales |
| Código abierto | Componentes de licencia libre, salvo comercialización como parte de sistema de alto riesgo |
| Uso privado | Uso personal y no comercial |

## Definiciones clave

| Término | Definición |
|---|---|
| Sistema de IA | Sistema basado en máquinas que infiere salidas (predicciones, contenidos, etc.) capaces de influir en entornos físicos o virtuales |
| Riesgo significativo | Combinación de probabilidad y gravedad del daño que puede afectar a las personas |
| Operadores de IA | Agrupa proveedores, implementadores, importadores, distribuidores y representantes autorizados |
| Sistema de IA de uso general | IA de propósito general con múltiples aplicaciones |

## Principios rectores

Fiscalizados por MCTCI, APDP y ANCI:

1. Intervención y supervisión humana
2. Solidez y seguridad técnica
3. Privacidad y gobernanza de datos
4. Transparencia y explicabilidad
5. Diversidad, no discriminación y equidad
6. Bienestar social y medioambiental
7. Rendición de cuentas y responsabilidad
8. Protección de derechos de consumidores

## Clasificación por nivel de riesgo

Enfoque regulatorio basado en riesgo, similar al modelo europeo.

| Categoría | Definición | Régimen |
|---|---|---|
| Riesgo inaceptable | Sistemas incompatibles con derechos fundamentales | Prohibidos absolutamente |
| Alto riesgo | Sistemas con riesgo significativo de perjuicio | Condicionados a requisitos obligatorios; lista definida por reglamento |
| Riesgo limitado | Sistemas con riesgos no significativos de manipulación o engaño | Reglas básicas de transparencia |
| Sin riesgo evidente | Sistemas sin riesgos significativos | Sin requisitos adicionales |

## Prácticas prohibidas (riesgo inaceptable)

| Letra | Práctica prohibida | Excepciones |
|---|---|---|
| a | Manipulación subliminal que cause daño físico o mental | Terapéutica consentida |
| b | Explotación de vulnerabilidades para inducir comportamientos dañinos | Especial protección a NNA |
| c | Categorización masiva basada en datos sensibles que provoque discriminación | Terapéutica consentida |
| d | Calificación social generalizada ("social scoring") con trato discriminatorio | — |
| e | Identificación biométrica remota en tiempo real en espacios públicos | Seguridad pública y persecución penal |
| f | Extracción masiva e indiscriminada de imágenes faciales ("facial scraping") | — |
| g | Evaluación de emociones en ámbitos sensibles (penal, laboral, educativo, etc.) | — |

## Requisitos obligatorios (alto riesgo)

| Requisito | Descripción |
|---|---|
| Gestión de riesgos | Sistema de gestión continuo durante todo el ciclo de vida |
| Gobernanza de datos | Estándares de seguridad y protección de datos |
| Documentación técnica | Documentación inteligible que demuestre cumplimiento |
| Registros (logs) | Funcionalidades de registro de eventos con almacenamiento seguro |
| Transparencia y explicabilidad | Nivel suficiente de transparencia para comprensión del funcionamiento |
| Supervisión humana | Mecanismos técnicos y operativos para supervisión por personal capacitado |
| Precisión, solidez y ciberseguridad | Seguridad desde el diseño, alineada con Ley Marco de Ciberseguridad |

**Flexibilidad proporcional**: reglamento podrá establecer estándares diferenciados para pymes.

## Obligaciones de riesgo limitado

- **Deber de transparencia**: informar a las personas que interactúan con un sistema de IA
- **Excepción**: no aplica para sistemas autorizados por ley con fines de investigación o enjuiciamiento penal

## Gestión de incidentes graves

- Cualquier persona puede reportar incidente grave a la APDP
- APDP informa al operador responsable para medidas de contención
- Si el incidente afecta operadores vitales: APDP se coordina con ANCI

## Gobernanza institucional

### Pilares

| Pilar | Órgano | Naturaleza | Función |
|---|---|---|---|
| 1 | Consejo Asesor Técnico de IA | Permanente, consultivo | Asesorar al MCTCI en implementación de la ley |
| 2 | APDP | Autoridad de fiscalización | Supervisar cumplimiento, determinar infracciones, ejercer potestad sancionadora |

### Actores clave

| Actor | Rol |
|---|---|
| Ministerio de Ciencia, Tecnología, Conocimiento e Innovación (MCTCI) | Cartera líder del proyecto |
| Cámara de Diputadas y Diputados | Corporación de origen; rol central de Comisión de Futuro |
| Corte Suprema | Consultada sobre aspectos que inciden en competencias judiciales |
| Consejo Asesor Técnico de IA | Órgano consultivo creado por la ley |
| Agencia de Protección de Datos Personales (APDP) | Autoridad de fiscalización y sanción |
| Consejo para la Transparencia | Acceso a información pública sobre IA |
| Agencia Nacional de Ciberseguridad (ANCI) | Gestión complementaria de incidentes de seguridad |
| Ministerios sectoriales, academia, sociedad civil, empresa privada | Otros actores participantes |

## Medidas de apoyo a la innovación

- **Sandboxes regulatorios**: espacios controlados de prueba para experimentar con innovaciones de IA en entornos restringidos y supervisados
- **Apoyo a pymes**: medidas de apoyo técnico y financiero para adopción de IA en empresas de menor tamaño

## Régimen sancionatorio y responsabilidad

- **Confidencialidad**: resguardo de información obtenida por autoridades durante fiscalización
- **Infracciones y sanciones**: catálogo de infracciones (leves, graves, muy graves); multas administrativas hasta 20.000 UTM para infracciones muy graves
- **Responsabilidad civil**: acciones civiles por daños causados por sistemas de IA
- **Potestad sancionadora**: recae en la APDP

## Disposiciones finales y transitorias

- **Propiedad intelectual**: excepción al derecho de autor para minería de datos (text and data mining) para desarrollo de IA
- **Vacatio legis**: normas transitorias establecen entrada en vigencia y plazos para dictar reglamentos

## Análisis de indicaciones

### Indicaciones del Ejecutivo

| Fecha | Contenido |
|---|---|
| 18 octubre 2024 | Aclarar tratamiento de "sistemas de IA de uso general"; naturaleza voluntaria de sandboxes |
| 4 marzo 2025 | Reforzar principios; redefinir usos de riesgo inaceptable; clarificar obligaciones alto riesgo; mejorar coordinación interinstitucional APDP-ANCI |
| 19 agosto 2025 | Ajustes finales; ratificar competencias del Consejo para la Transparencia; ampliar funciones del Consejo Asesor de IA; facilitar acceso a datos en sandboxes |

### Indicación parlamentaria

- **Fecha**: 4 agosto 2025
- **Autora**: Diputada Mónica Arce
- **Contenido**: agregar vulneración a Ley 21.430 (Garantías de la Niñez y Adolescencia) como definición de "incidente grave"

## Puntos controversiales

| Tema | Descripción |
|---|---|
| Ámbito de aplicación | Exclusión de sistemas de defensa nacional y potencial vacío legal en actividades de I+D |
| Excepciones riesgo inaceptable | Permiso para identificación biométrica remota por parte de la policía |
| Delegación reglamentaria | Inquietud por delegar lista de IA de alto riesgo a reglamento del Ejecutivo |
| Enfoque en usos | Responsabilidad recae en implementadores; complejidad para desarrolladores originales |
| IA de uso general | Dificultad de hacer cumplir obligaciones a desarrolladores de modelos fundacionales extranjeros |
| Régimen sancionatorio | Proporcionalidad de multas, especialmente para pymes |
| Capacidad institucional | Duda sobre recursos técnicos y financieros de APDP para fiscalización eficaz |
| Propiedad intelectual | Tensión entre acceso a datos para innovación y protección de derechos de autor |

## Cronología legislativa

| Fecha | Hito |
|---|---|
| 24 abril 2023 | Presentación moción parlamentaria (boletín 15.869-19) |
| 7 mayo 2024 | Ingreso mensaje presidencial (boletín 16.821-19) |
| 21 junio 2024 | Recepción informe Corte Suprema |
| ~3 julio 2024 | Aprobación en general en Comisión de Futuro |
| 18 octubre 2024 | Primera ronda de indicaciones del Ejecutivo |
| 4 marzo 2025 | Segunda ronda de indicaciones del Ejecutivo |
| 4 agosto 2025 | Aprobación en general en Sala de Cámara de Diputados |
| 19 agosto 2025 | Tercera ronda de indicaciones del Ejecutivo |

**Próximos pasos**: votación en particular en la Cámara y posterior trámite en el Senado.
